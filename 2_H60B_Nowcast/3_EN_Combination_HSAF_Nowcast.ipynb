{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination of the HSAF-H60B observation and nowcast scripts\n",
    "\n",
    "This script combines the previous scripts for downloading and pre-processing HSAF observations, and subsequently creating a nowcast. Unlike the earlier scripts, which included numerous plotting and visualization steps to explain the workflow in detail, this version focuses solely on producing observation and nowcast outputs the same output.\n",
    "\n",
    "You can specify your preferred settings in the first cell of the script. After that, simply use \"Run All,\" and all parameters will automatically be applied throughout the script. This streamlined approach makes the script more suitable for operational use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries have been successfully imported!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import gzip\n",
    "import shutil\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta, date\n",
    "from ftplib import FTP\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import BoundaryNorm, ListedColormap\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import rioxarray\n",
    "from pyproj import CRS\n",
    "from pyresample.geometry import AreaDefinition\n",
    "try:\n",
    "    from satpy.readers.core._geos_area import get_area_extent\n",
    "except ImportError:\n",
    "    from satpy.readers._geos_area import get_area_extent\n",
    "from enhanced_steps import EnhancedStepsNowcast\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import gzip\n",
    "import shutil\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta, date\n",
    "from ftplib import FTP\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import BoundaryNorm, ListedColormap\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import rioxarray\n",
    "from pyproj import CRS\n",
    "from pyresample.geometry import AreaDefinition\n",
    "try:\n",
    "    from satpy.readers.core._geos_area import get_area_extent\n",
    "except ImportError:\n",
    "    from satpy.readers._geos_area import get_area_extent\n",
    "from enhanced_steps import EnhancedStepsNowcast\n",
    "from PIL import Image, ImageSequence, ImageDraw, ImageFont\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "print(\"All libraries have been successfully imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script Settings and Output Options\n",
    "\n",
    "To run the script, you have a few configuration options.\n",
    "- If you set selection_mode to \"Current\", the script will automatically select the most recent available data.\n",
    "- If you want to run the script for a historical period, use the \"Select_target_data\" option.\n",
    "\n",
    "Additionally, you can choose which outputs to generate: GIF animations, Excel time series, and graphs. These outputs will not be displayed within the script itself, but will be automatically saved in the designated output folder structure.\n",
    "\n",
    "You can control which outputs are created by setting the corresponding options to True or False according to your preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-30 15:00:00\n"
     ]
    }
   ],
   "source": [
    "username = \"xxxxxxx\"                                                    # Replace with your actual username\n",
    "password = \"xxxxxxx\"                                                    # Replace with your actual password\n",
    "\n",
    "# Selection mode: \"Select_target_data\" or \"Current\"\n",
    "\n",
    "selection_mode = \"Select_target_data\"  \n",
    "# selection_mode = \"Current\"  \n",
    "\n",
    "if selection_mode == \"Current\":\n",
    "    now = datetime.utcnow()  \n",
    "    minute = (now.minute // 15) * 15                                    # Round down to nearest 15 minutes\n",
    "    target_datetime = now.replace(minute=minute, second=0, microsecond=0)\n",
    "    print(target_datetime)\n",
    "\n",
    "if selection_mode == \"Select_target_data\":\n",
    "    target_datetime = datetime(2025, 8, 30, 15, 0)                      # Start point for data selection\n",
    "    print(target_datetime)\n",
    "\n",
    "make_gif = True                                                         # True to create a GIF animation, False otherwise\n",
    "make_timeseries_Excel = True                                            # True to generate an Excel file with the time series\n",
    "make_graph = True                                                       # True to create plots\n",
    "\n",
    "n_steps = 10                                                            # Number of steps to process\n",
    "region = {\"lat_min\": 4, \"lat_max\": 16, \"lon_min\": -6, \"lon_max\": 3}     # Region of interest (latitude/longitude)\n",
    "ensemble_number = 2                                                     # Ensemble member number to use\n",
    "\n",
    "points_of_interest = [\n",
    "    {\"name\": \"Nouna\", \"lat\": 12.76, \"lon\": -3.84},                      # Point of interest 1\n",
    "    {\"name\": \"Kante\", \"lat\": 9.961861, \"lon\": 1.042944},                # Point of interest 2\n",
    "]\n",
    "\n",
    "# Visualization parameters\n",
    "bounds = [0, 0.5, 2, 5, 10, 15, 25, 40, 100]                            # Colorbar boundaries\n",
    "colors = [\"#ffffff\", \"#add8e6\", \"#0000ff\", \"#00ff00\",\n",
    "          \"#ffff00\", \"#ffa500\", \"#ff0000\", \"#ff69b4\", \"#ff69b4\"]        # Colors for each interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders\n",
    "data_folder = Path(\"./h60b_data\")\n",
    "raw_folder = data_folder / \"raw\"\n",
    "processed_folder = data_folder / \"processed\"\n",
    "nowcasting_folder = data_folder / \"nowcast\"\n",
    "\n",
    "# Create directories if they do not exist yet\n",
    "raw_folder.mkdir(parents=True, exist_ok=True)\n",
    "processed_folder.mkdir(parents=True, exist_ok=True)\n",
    "Path(nowcasting_folder).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the HSAF FTP server...\n",
      "Connection successful!\n",
      "Latest available file: h60_20251010_1115_fdk.nc.gz (2025-10-10 11:15:00)\n"
     ]
    }
   ],
   "source": [
    "# HSAF FTP server details\n",
    "ftp_server = \"ftphsaf.meteoam.it\"\n",
    "ftp_directory = \"./h60B/h60_cur_mon_data/\"\n",
    "\n",
    "def parse_h60b_timestamp(filename):\n",
    "    try:\n",
    "        parts = filename.split(\"_\")\n",
    "        date_str = parts[1]                  # YYYYMMDD\n",
    "        time_str = parts[2].split(\".\")[0]    # HHMM\n",
    "        timestamp = datetime.strptime(f\"{date_str}{time_str}\", \"%Y%m%d%H%M\")\n",
    "        return timestamp\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def list_h60b_files_full():\n",
    "    try:\n",
    "        print(\"Connecting to the HSAF FTP server...\")\n",
    "        with FTP(ftp_server) as ftp:\n",
    "            # Login with credentials\n",
    "            ftp.login(username, password)\n",
    "            print(\"Connection successful!\")\n",
    "            ftp.cwd(ftp_directory)\n",
    "            files = []\n",
    "            ftp.dir(lambda line: files.append(line.split()[-1]))\n",
    "            h60b_files = [f for f in files if f.startswith(\"h60\")]\n",
    "            timestamps_files = [(parse_h60b_timestamp(f), f) \n",
    "                                for f in h60b_files \n",
    "                                if parse_h60b_timestamp(f) is not None]\n",
    "            \n",
    "            if not timestamps_files:\n",
    "                print(\"No files with valid timestamp found.\")\n",
    "                return []\n",
    "            \n",
    "            timestamps_files.sort()\n",
    "            \n",
    "            first_file = timestamps_files[0]\n",
    "            last_file  = timestamps_files[-1]\n",
    "            print(f\"Latest available file: {last_file[1]} ({last_file[0]})\")\n",
    "            return [f[1] for f in timestamps_files]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to FTP: {e}\")\n",
    "        print(\"Make sure you are registered at https://hsaf.meteoam.it/ and have valid credentials\")\n",
    "        return []\n",
    "    \n",
    "all_files = list_h60b_files_full()\n",
    "timestamps_files = [(parse_h60b_timestamp(f), f) for f in all_files if parse_h60b_timestamp(f)]\n",
    "timestamps_files.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_files_before_date(target_time=None, n_steps=10, timestamps_files=timestamps_files, current=False):\n",
    "    if not timestamps_files:\n",
    "        print(\"No files available for selection.\")\n",
    "        return []\n",
    "\n",
    "    if current:\n",
    "        selected = timestamps_files[-n_steps:] if n_steps <= len(timestamps_files) else timestamps_files\n",
    "        return [f[1] for f in selected]\n",
    "\n",
    "    if target_time is None:\n",
    "        print(\"Error: target_time must be provided if 'current' is False.\")\n",
    "        return []\n",
    "\n",
    "    selected_files = []\n",
    "    current_ts = target_time\n",
    "\n",
    "    for _ in range(n_steps):\n",
    "        previous_file = None\n",
    "        for ts, f in reversed(timestamps_files):\n",
    "            if ts <= current_ts:\n",
    "                previous_file = (ts, f)\n",
    "                break\n",
    "\n",
    "        if previous_file:\n",
    "            selected_files.append(previous_file[1])\n",
    "            current_ts = previous_file[0] - timedelta(minutes=15)\n",
    "        else:\n",
    "            print(f\"No file available before {current_ts}\")\n",
    "            break\n",
    "\n",
    "    return selected_files[::-1]\n",
    "\n",
    "if selection_mode == \"Select_target_data\":\n",
    "    selected_files = select_files_before_date(target_datetime, n_steps=n_steps, current=False)\n",
    "elif selection_mode == \"Current\":\n",
    "    selected_files = select_files_before_date(target_datetime, n_steps=n_steps, current=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_h60b_file(filename, output_folder=None):\n",
    "\n",
    "    target_folder = Path(output_folder) if output_folder else raw_folder\n",
    "    target_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    gz_path = target_folder / filename\n",
    "    nc_path = target_folder / filename.replace(\".gz\", \"\")\n",
    "\n",
    "    if nc_path.exists():\n",
    "        print(f\"The file already exists: {nc_path.name}\")\n",
    "        return str(nc_path)\n",
    "\n",
    "    try:\n",
    "        print(f\"Downloading {filename}...\")\n",
    "\n",
    "        with FTP(ftp_server) as ftp:\n",
    "            ftp.login(username, password)\n",
    "            ftp.cwd(ftp_directory)\n",
    "\n",
    "            with open(gz_path, \"wb\") as f:\n",
    "                ftp.retrbinary(f\"RETR {filename}\", f.write)\n",
    "\n",
    "        file_size = gz_path.stat().st_size / (1024*1024)  \n",
    "        with gzip.open(gz_path, \"rb\") as f_in:\n",
    "            with open(nc_path, \"wb\") as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        gz_path.unlink()\n",
    "\n",
    "        final_size = nc_path.stat().st_size / (1024*1024) \n",
    "\n",
    "        return str(nc_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {filename}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_file(raw_file: str, output_folder=None):\n",
    "    \n",
    "    target_folder = Path(output_folder) if output_folder else processed_folder\n",
    "    target_folder.mkdir(parents=True, exist_ok=True)\n",
    "    filename = Path(raw_file).name\n",
    "\n",
    "    # Extract timestamp from the filename and define the output path\n",
    "    timestamp = parse_h60b_timestamp(filename)\n",
    "    hsaf_filename = f\"HSAF-H60B_{timestamp.strftime('%Y%m%dT%H%M%S')}.nc\"\n",
    "    output_path_HSAF = target_folder / hsaf_filename\n",
    "\n",
    "    # Check if preprocessed file already exists\n",
    "    if output_path_HSAF.exists():\n",
    "        print(f\"File already preprocessed: {hsaf_filename} -> Skipping preprocessing\")\n",
    "        return str(output_path_HSAF)\n",
    "\n",
    "    # --- Define coordinate systems ---\n",
    "    crs_in = \"+proj=geos +a=6378.169 +b=6356.584 +h=35785.831 +lat_0=0 +lon_0=0.000000\"  # Original CRS (satellite)\n",
    "    crs_out = \"EPSG:4326\"  # Output CRS: latitude/longitude\n",
    "\n",
    "    ds = xr.open_dataset(raw_file, decode_coords=\"all\", decode_cf=False)\n",
    "    ds = ds.rename({\"nx\": \"x\", \"ny\": \"y\"})\n",
    "    rr_raw = ds[\"rr\"]\n",
    "    scale_factor = rr_raw.encoding.get(\"scale_factor\", 0.1)\n",
    "    add_offset  = rr_raw.encoding.get(\"add_offset\", 0.0)\n",
    "    ds[\"rr\"] = rr_raw.astype(\"float32\") * scale_factor + add_offset\n",
    "    ds[\"rr\"].encoding.clear()\n",
    "    ds[\"rr\"].attrs.clear()\n",
    "    ds = ds[[\"rr\"]].astype(\"float32\")\n",
    "\n",
    "    source_crs = CRS.from_proj4(ds.attrs[\"gdal_projection\"])\n",
    "    crs_in = source_crs.to_proj4()  # Exact CRS of the file\n",
    "    crs_out = \"EPSG:4326\"\n",
    "\n",
    "    cgms_projection = (\n",
    "        \"+proj=geos +coff=1856.000000 +cfac=13642337.000000 \"\n",
    "        \"+loff=1856.000000 +lfac=13642337.000000 \"\n",
    "        \"+spp=0.000000 +r_eq=6378.169000 +r_pol=6356.583800 +h=42164.000000\"\n",
    "    )\n",
    "    matches = re.findall(r\"\\+?(\\w+)\\s*=\\s*([^\\s]+)\", cgms_projection)\n",
    "    parse_dict = {k: v for k, v in matches}\n",
    "    cd = source_crs.to_dict()\n",
    "    area_extent = get_area_extent({\n",
    "        \"scandir\": \"N2S\",                             # Scan direction of satellite (N2S = North to South)\n",
    "        \"h\": float(parse_dict[\"h\"]) * 1000 - float(parse_dict[\"r_eq\"]) * 1000,  # Satellite height above Earth\n",
    "        \"loff\": float(parse_dict[\"loff\"]),            # Line and column offsets\n",
    "        \"coff\": float(parse_dict[\"coff\"]),           \n",
    "        \"lfac\": float(parse_dict[\"lfac\"]),            # Scale factors for lines and columns\n",
    "        \"cfac\": float(parse_dict[\"cfac\"]),\n",
    "        \"ncols\": ds.x.size,                           # Number of columns and rows\n",
    "        \"nlines\": ds.y.size,\n",
    "    })\n",
    "\n",
    "    area_def_src = AreaDefinition(\n",
    "        \"areaD\",\n",
    "        cd[\"proj\"],\n",
    "        \"areaD\",\n",
    "        {\"lon_0\": cd[\"lon_0\"], \"a\": cd[\"a\"], \"b\": cd[\"b\"], \"h\": cd[\"h\"], \"proj\": cd[\"proj\"]},\n",
    "        ds.y.size,\n",
    "        ds.x.size,\n",
    "        (area_extent[0], area_extent[1], area_extent[2], area_extent[3]),\n",
    "    )\n",
    "\n",
    "    # Create new X and Y coordinates\n",
    "    x, y = area_def_src.get_proj_coords()\n",
    "    new_x_coords = np.linspace(x.min(), x.max(), num=ds.sizes[\"x\"])\n",
    "    new_y_coords = np.linspace(y.max(), y.min(), num=ds.sizes[\"y\"])\n",
    "    ds = ds.assign_coords(y=(\"y\", new_y_coords), x=(\"x\", new_x_coords))\n",
    "\n",
    "    # Write CRS corresponding to coordinate units\n",
    "    ds = ds.rio.write_crs(crs_in)\n",
    "    ds = ds.rename({\"rr\": \"precip_intensity\"}).sortby(\"y\")\n",
    "    ds = ds.expand_dims(\"time\").assign_coords(time=(\"time\", [timestamp]))\n",
    "    ds = ds.transpose(\"time\", \"y\", \"x\")\n",
    "    ds.precip_intensity.attrs = {\n",
    "        \"standard_name\": \"precipitation_flux\",\n",
    "        \"long_name\": \"Precipitation flux derived from cloud optical properties\",\n",
    "        \"units\": \"kg m-2 h-1\",\n",
    "    }\n",
    "\n",
    "    ds[\"precip_intensity\"] = ds[\"precip_intensity\"].where(ds[\"precip_intensity\"] >= 0, np.nan)\n",
    "    da = ds[\"precip_intensity\"].rio.write_nodata(np.nan, encoded=True)\n",
    "    ds[\"precip_intensity\"] = da\n",
    "    ds = ds.rio.reproject(crs_out, nodata=np.nan)\n",
    "\n",
    "    # Clear encoding after reprojection\n",
    "    for var_name in ds.data_vars:\n",
    "        ds[var_name].encoding.clear()\n",
    "        for attr in [\"_FillValue\", \"missing_value\", \"fill_value\", \"FillValue\"]:\n",
    "            ds[var_name].attrs.pop(attr, None)\n",
    "\n",
    "    # Final dimension order\n",
    "    ds = ds.transpose(\"time\", \"y\", \"x\")\n",
    "\n",
    "    # Set CF attributes for coordinates\n",
    "    ds.x.attrs = {\"standard_name\": \"longitude\", \"long_name\": \"longitude\", \"units\": \"degrees_east\", \"axis\": \"X\"}\n",
    "    ds.y.attrs = {\"standard_name\": \"latitude\", \"long_name\": \"latitude\", \"units\": \"degrees_north\", \"axis\": \"Y\"}\n",
    "    ds.time.attrs = {\"standard_name\": \"time\", \"long_name\": \"time\", \"axis\": \"T\"}\n",
    "\n",
    "    # Set global dataset attributes\n",
    "    ds.attrs = {\n",
    "        \"Conventions\": \"CF-1.6\",\n",
    "        \"title\": \"RAINSAT H60B MSG SEVIRI Precipitation\",\n",
    "        \"source\": \"EUMETSAT H-SAF H60B\",\n",
    "        \"creator\": \"HKV services\",\n",
    "        \"creation_date\": date.today().strftime(\"%Y-%m-%d\"),\n",
    "        \"time_coverage_start\": timestamp.strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
    "        \"time_coverage_end\": (timestamp + timedelta(minutes=15)).strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
    "        \"geospatial_lat_min\": float(ds.y.min()),\n",
    "        \"geospatial_lat_max\": float(ds.y.max()),\n",
    "        \"geospatial_lon_min\": float(ds.x.min()),\n",
    "        \"geospatial_lon_max\": float(ds.x.max()),\n",
    "        \"crs\": crs_out,\n",
    "        \"product_details\": \"https://hsaf.meteoam.it/Products/Detail?prod=H60B\",\n",
    "        \"data_source\": \"hsaf-h60b\",\n",
    "    }\n",
    "\n",
    "    # NetCDF encoding\n",
    "    encoding = {\n",
    "        \"precip_intensity\": {\"dtype\": \"float32\", \"zlib\": True, \"complevel\": 4, \"_FillValue\": -999.0},\n",
    "        \"time\": {\"units\": \"minutes since 1970-01-01 00:00:00\", \"dtype\": \"float64\"},\n",
    "    }\n",
    "\n",
    "    # Save preprocessed NetCDF file\n",
    "    ds.to_netcdf(output_path_HSAF, encoding=encoding)\n",
    "    ds.close()\n",
    "    print(f\"H60B file successfully preprocessed: {hsaf_filename}\")\n",
    "    return str(output_path_HSAF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading h60_20250830_1245_fdk.nc.gz...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H60B file successfully preprocessed: HSAF-H60B_20250830T124500.nc\n",
      "h60_20250830_1245_fdk.nc.gz processed\n",
      "----------------------------------------\n",
      "Downloading h60_20250830_1300_fdk.nc.gz...\n",
      "H60B file successfully preprocessed: HSAF-H60B_20250830T130000.nc\n",
      "h60_20250830_1300_fdk.nc.gz processed\n",
      "----------------------------------------\n",
      "Downloading h60_20250830_1315_fdk.nc.gz...\n",
      "H60B file successfully preprocessed: HSAF-H60B_20250830T131500.nc\n",
      "h60_20250830_1315_fdk.nc.gz processed\n",
      "----------------------------------------\n",
      "Downloading h60_20250830_1330_fdk.nc.gz...\n",
      "H60B file successfully preprocessed: HSAF-H60B_20250830T133000.nc\n",
      "h60_20250830_1330_fdk.nc.gz processed\n",
      "----------------------------------------\n",
      "Downloading h60_20250830_1345_fdk.nc.gz...\n",
      "H60B file successfully preprocessed: HSAF-H60B_20250830T134500.nc\n",
      "h60_20250830_1345_fdk.nc.gz processed\n",
      "----------------------------------------\n",
      "Downloading h60_20250830_1400_fdk.nc.gz...\n",
      "H60B file successfully preprocessed: HSAF-H60B_20250830T140000.nc\n",
      "h60_20250830_1400_fdk.nc.gz processed\n",
      "----------------------------------------\n",
      "Downloading h60_20250830_1415_fdk.nc.gz...\n",
      "H60B file successfully preprocessed: HSAF-H60B_20250830T141500.nc\n",
      "h60_20250830_1415_fdk.nc.gz processed\n",
      "----------------------------------------\n",
      "Downloading h60_20250830_1430_fdk.nc.gz...\n",
      "H60B file successfully preprocessed: HSAF-H60B_20250830T143000.nc\n",
      "h60_20250830_1430_fdk.nc.gz processed\n",
      "----------------------------------------\n",
      "Downloading h60_20250830_1445_fdk.nc.gz...\n",
      "H60B file successfully preprocessed: HSAF-H60B_20250830T144500.nc\n",
      "h60_20250830_1445_fdk.nc.gz processed\n",
      "----------------------------------------\n",
      "Downloading h60_20250830_1500_fdk.nc.gz...\n",
      "H60B file successfully preprocessed: HSAF-H60B_20250830T150000.nc\n",
      "h60_20250830_1500_fdk.nc.gz processed\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Final loop to download and preprocess the selected files\n",
    "for selected_file in selected_files:\n",
    "    downloaded_file = download_h60b_file(selected_file)\n",
    "    timestamp = parse_h60b_timestamp(Path(downloaded_file).name)\n",
    "    hsaf_filename = f\"HSAF-H60B_{timestamp.strftime('%Y%m%dT%H%M%S')}.nc\"\n",
    "    output_path_HSAF = processed_folder / hsaf_filename\n",
    "\n",
    "    if output_path_HSAF.exists():\n",
    "        print(f\"{hsaf_filename} already exists, skipping to the next file\\n\" + \"-\"*40)\n",
    "        continue\n",
    "    \n",
    "    preprocess_file(downloaded_file)\n",
    "    print(f\"{selected_file} processed\\n\" + \"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"data_source\": \"h60b\",        # Data source\n",
    "    \"ensemble\": 5,                # Number of ensemble members\n",
    "    \"n_input_files\": 10,          # Number of input files to use\n",
    "    \"n_lead_times\": 12,           # Number of forecast time steps (each step is 15 minutes)\n",
    "    \"frequency\": 15,              # Minutes between each time step\n",
    "    \"transform\": \"dB\",            # Transformation used by pysteps (\"dB\", \"log\", etc.)\n",
    "    \"threshold\": 0.05,            # Threshold (mm/h) to define rain/no rain\n",
    "    \"buffer_distance\": 5000,      # Buffer distance (meters) around the country for clipping\n",
    "    \"crs_out\": \"EPSG:4326\",       # Output coordinate reference system\n",
    "    \"norain_thr\": 0.005,          # Parameter for the Norain method\n",
    "    \"zerovalue\": -15.0,           # Parameter for the Norain method\n",
    "    \"max_workers\": 2,             # Number of processors to use\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_files_by_timestamp(selected_files, processed_folder):\n",
    "\n",
    "    processed_folder = Path(processed_folder)\n",
    "    all_files = list(processed_folder.glob(\"*\"))\n",
    "\n",
    "    # Extract timestamps from the selected files\n",
    "    ts_list = []\n",
    "    pattern_selected = r\"(\\d{8}_\\d{4})\"\n",
    "    for f in selected_files:\n",
    "        match = re.search(pattern_selected, f)\n",
    "        if match:\n",
    "            dt = datetime.strptime(match.group(), \"%Y%m%d_%H%M\")\n",
    "            ts_list.append(dt)\n",
    "\n",
    "    # Match with processed files based on timestamp\n",
    "    matched_files = []\n",
    "    pattern_processed = r\"(\\d{8}T\\d{6})\"  \n",
    "    for f in all_files:\n",
    "        match = re.search(pattern_processed, f.name)\n",
    "        if match:\n",
    "            dt_f = datetime.strptime(match.group(), \"%Y%m%dT%H%M%S\")\n",
    "            if dt_f in ts_list:\n",
    "                matched_files.append(f)\n",
    "\n",
    "    matched_files.sort(key=lambda x: re.search(pattern_processed, x.name).group())\n",
    "    return matched_files\n",
    "\n",
    "observations_input_nowcast = match_files_by_timestamp(selected_files, processed_folder)\n",
    "\n",
    "\n",
    "def open_as_time_stack(input_files):\n",
    "    \"\"\"\n",
    "    Open multiple NetCDF files as a single time-stacked xarray Dataset.\n",
    "    \"\"\"\n",
    "    if not input_files:\n",
    "        raise FileNotFoundError(\"No input files found.\")\n",
    "    datasets = xr.open_mfdataset(input_files)                       \n",
    "    return datasets\n",
    "\n",
    "# Load the preprocessed observations as a time-stacked dataset\n",
    "input_dataset = open_as_time_stack(observations_input_nowcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rain fraction is: 0.008419090835426626, while minimum fraction is 0.005\n",
      "unknown projection longlat\n",
      "Inputs validated and initialized successfully.\n",
      "Computing STEPS nowcast\n",
      "-----------------------\n",
      "\n",
      "Inputs\n",
      "------\n",
      "input dimensions: 287x215\n",
      "km/pixel:         3.0\n",
      "time step:        15 minutes\n",
      "\n",
      "Methods\n",
      "-------\n",
      "extrapolation:          semilagrangian\n",
      "bandpass filter:        gaussian\n",
      "decomposition:          fft\n",
      "noise generator:        nonparametric\n",
      "noise adjustment:       no\n",
      "velocity perturbator:   None\n",
      "conditional statistics: no\n",
      "precip. mask method:    incremental\n",
      "probability matching:   cdf\n",
      "FFT method:             numpy\n",
      "domain:                 spatial\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "number of time steps:     12\n",
      "ensemble size:            5\n",
      "parallel threads:         2\n",
      "number of cascade levels: 6\n",
      "order of the AR(p) model: 2\n",
      "precip. intensity threshold: -13.010299956639813\n",
      "Nowcast components initialized successfully.\n",
      "Rain fraction is: 0.005234583907300867, while minimum fraction is 0.0\n",
      "Extrapolation complete and precipitation fields aligned.\n",
      "************************************************\n",
      "* Correlation coefficients for cascade levels: *\n",
      "************************************************\n",
      "-----------------------------------------\n",
      "| Level |     Lag-1     |     Lag-2     |\n",
      "-----------------------------------------\n",
      "| 1     | 0.989241      | 0.969399      |\n",
      "-----------------------------------------\n",
      "| 2     | 0.978524      | 0.962926      |\n",
      "-----------------------------------------\n",
      "| 3     | 0.875346      | 0.823680      |\n",
      "-----------------------------------------\n",
      "| 4     | 0.531721      | 0.331582      |\n",
      "-----------------------------------------\n",
      "| 5     | 0.405226      | 0.198900      |\n",
      "-----------------------------------------\n",
      "| 6     | -0.027365     | -0.016665     |\n",
      "-----------------------------------------\n",
      "****************************************\n",
      "* AR(p) parameters for cascade levels: *\n",
      "****************************************\n",
      "------------------------------------------------------\n",
      "| Level |    Phi-1     |    Phi-2     |    Phi-0     |\n",
      "------------------------------------------------------\n",
      "| 1     | 1.414460     | -0.429844    | 0.132088     |\n",
      "------------------------------------------------------\n",
      "| 2     | 0.853803     | 0.127459     | 0.204450     |\n",
      "------------------------------------------------------\n",
      "| 3     | 0.660229     | 0.245751     | 0.468669     |\n",
      "------------------------------------------------------\n",
      "| 4     | 0.495504     | 0.068112     | 0.844953     |\n",
      "------------------------------------------------------\n",
      "| 5     | 0.388406     | 0.041508     | 0.913429     |\n",
      "------------------------------------------------------\n",
      "| 6     | -0.027370    | -0.000187    | 0.999626     |\n",
      "------------------------------------------------------\n",
      "AR model and noise applied to precipitation cascades.\n",
      "Velocity perturbations initialized successfully.\n",
      "Precipitation mask initialized successfully.\n",
      "FFT objects initialized successfully.\n",
      "Starting nowcast computation.\n",
      "Computing nowcast for time step 1... done.\n",
      "Computing nowcast for time step 2... done.\n",
      "Computing nowcast for time step 3... done.\n",
      "Computing nowcast for time step 4... done.\n",
      "Computing nowcast for time step 5... done.\n",
      "Computing nowcast for time step 6... done.\n",
      "Computing nowcast for time step 7... done.\n",
      "Computing nowcast for time step 8... done.\n",
      "Computing nowcast for time step 9... done.\n",
      "Computing nowcast for time step 10... done.\n",
      "Computing nowcast for time step 11... done.\n",
      "Computing nowcast for time step 12... done.\n"
     ]
    }
   ],
   "source": [
    "# Remove existing nowcast file if it exists\n",
    "nc_path = Path(\"h60b_data/nowcast/pysteps_h60b_latest.nc\")\n",
    "if nc_path.exists():\n",
    "    nc_path.unlink()\n",
    "\n",
    "steps_settings = {\n",
    "    \"datafolder\": data_folder,                      # Folder containing preprocessed HSAF files\n",
    "    \"ensemble\": settings[\"ensemble\"],               # Number of ensemble members\n",
    "    \"n_lead_times\": settings[\"n_lead_times\"],       # Number of lead times to forecast\n",
    "    \"frequency\": settings[\"frequency\"],             # Time step frequency (minutes)\n",
    "    \"transform\": settings[\"transform\"],             # PySTEPS transformation (\"dB\", \"log\", etc.)\n",
    "    \"threshold\": settings[\"threshold\"],             # Threshold to distinguish rain / no rain\n",
    "    \"buffer_distance\": settings[\"buffer_distance\"], # Buffer distance around the region of interest\n",
    "    \"crs_out\": settings[\"crs_out\"],                 # Output coordinate reference system\n",
    "    \"norain_thr\": settings[\"norain_thr\"],           # Parameter for \"no rain\" handling\n",
    "    \"zerovalue\": settings[\"zerovalue\"],             # Minimum value for \"no rain\"\n",
    "    \"max_workers\": settings[\"max_workers\"],         # Number of CPUs to use\n",
    "}\n",
    "\n",
    "engine = EnhancedStepsNowcast(steps_settings, \"h60b\")\n",
    "dataset_roi = input_dataset.sel(\n",
    "    x=slice(region[\"lon_min\"], region[\"lon_max\"]),\n",
    "    y=slice(region[\"lat_max\"], region[\"lat_min\"])  # Note: Y coordinates might be inverted\n",
    ")\n",
    "\n",
    "nowcast_arrays, metadata = engine.nowcast_steps_pysteps(dataset_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folder for the nowcast results\n",
    "output_path_nowcast = \"/workspaces/Tools-for-weather-and-climate-services-in-Africa/2_H60B_Nowcast/h60b_data/nowcast\"\n",
    "Path(output_path_nowcast).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "engine.settings[\"threddsdata\"] = output_path_nowcast\n",
    "\n",
    "country_name = f\"Country_{target_datetime.strftime('%Y%m%dT%H%M')}\"\n",
    "\n",
    "engine.export_nowcast_to_netcdf(\n",
    "    country=country_name,\n",
    "    nowcasting_arrays=nowcast_arrays,\n",
    "    date_start=None,       # Automatically use the first time step\n",
    "    metadata=metadata,\n",
    "    reproject=True,\n",
    "    data_source=settings[\"data_source\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options to visualise and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GIFs for the observations\n",
    "if make_gif:\n",
    "    obs_files = []\n",
    "    pattern = r\"\\d{8}T\\d{4}\"  # Timestamp pattern  \n",
    "\n",
    "    for f in observations_input_nowcast:\n",
    "        match = re.search(pattern, str(f))  \n",
    "        if match:\n",
    "            ts_str = match.group()\n",
    "            matching = list(processed_folder.glob(f\"*{ts_str}*.nc\"))\n",
    "            obs_files.extend(matching)\n",
    "        else:\n",
    "            print(f\"No timestamp found in: {f}\")\n",
    "\n",
    "    if not obs_files:\n",
    "        print(\"No observation files found for the selected time steps.\")\n",
    "    else:\n",
    "        ds_obs = xr.open_mfdataset([str(f) for f in obs_files])\n",
    "\n",
    "        # Region of Interest\n",
    "        ds_roi = ds_obs.sel(\n",
    "            x=slice(region[\"lon_min\"], region[\"lon_max\"]),\n",
    "            y=slice(region[\"lat_max\"], region[\"lat_min\"])\n",
    "        )\n",
    "\n",
    "        var = ds_roi[\"precip_intensity\"] if \"precip_intensity\" in ds_roi.data_vars else ds_roi[\"precipitation\"]\n",
    "        x = var[\"x\"].values\n",
    "        y = var[\"y\"].values\n",
    "\n",
    "        if y[0] > y[-1]:\n",
    "            extent = [x.min(), x.max(), y.max(), y.min()]\n",
    "            origin = \"upper\"\n",
    "        else:\n",
    "            extent = [x.min(), x.max(), y.min(), y.max()]\n",
    "            origin = \"lower\"\n",
    "\n",
    "        cmap = ListedColormap(colors)\n",
    "        norm = BoundaryNorm(boundaries=bounds, ncolors=cmap.N, extend='max')\n",
    "        cmap.set_bad(\"none\")\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(5, 6), subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "        plt.close(fig)\n",
    "        ax.set_extent([x.min(), x.max(), y.min(), y.max()])\n",
    "        ax.coastlines(resolution='10m', color='black')\n",
    "        ax.add_feature(cfeature.BORDERS, edgecolor='black')\n",
    "\n",
    "        last_frame = var.isel(time=-1)\n",
    "        last_frame_flipped = np.ma.masked_invalid(last_frame.values[::-1, :]).astype(np.float32)\n",
    "\n",
    "        img = ax.imshow(\n",
    "            last_frame_flipped,\n",
    "            extent=extent,\n",
    "            origin=origin,\n",
    "            cmap=cmap,\n",
    "            norm=norm\n",
    "        )\n",
    "\n",
    "        cbar = fig.colorbar(img, ax=ax, fraction=0.05, pad=0.02, ticks=bounds)\n",
    "        cbar.set_label(\"Precipitation (mm/h)\")\n",
    "        ax.set_title(np.datetime_as_string(last_frame.time.values, unit='m'))\n",
    "\n",
    "        def update(i):\n",
    "            frame = var.isel(time=i)\n",
    "            frame_flipped = np.ma.masked_invalid(frame.values[::-1, :]).astype(np.float32)\n",
    "            img.set_data(frame_flipped)\n",
    "            ax.set_title(np.datetime_as_string(frame.time.values, unit='m'))\n",
    "            return (img,)\n",
    "\n",
    "        ani = FuncAnimation(fig, update, frames=var.sizes[\"time\"], interval=600, blit=True)\n",
    "\n",
    "        results_folder = Path(\"results\")\n",
    "        results_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        last_time = var.time.values[9]\n",
    "        last_time_dt = pd.to_datetime(last_time)\n",
    "        safe_time_str = last_time_dt.strftime(\"%Y%m%dT%H%M\")\n",
    "\n",
    "        time_folder = results_folder / f\"ens_{ensemble_number}_{safe_time_str}\"\n",
    "        time_folder.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        gif_filename = f\"observations_animation_{safe_time_str}.gif\"\n",
    "        gif_path = time_folder / gif_filename\n",
    "        ani.save(gif_path, writer=\"pillow\", fps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GIFs for the nowcast\n",
    "if make_gif:\n",
    "    ds_nowcast = xr.open_dataset(nowcasting_folder / \"pysteps_h60b_latest.nc\")\n",
    "    varname = \"precip_intensity\" if \"precip_intensity\" in ds_nowcast.data_vars else \"precipitation\"\n",
    "    var = ds_nowcast[varname]\n",
    "    ds_nowcast.close()\n",
    "\n",
    "    if \"ens_number\" in var.dims:\n",
    "        var = var.isel(ens_number=ensemble_number)\n",
    "\n",
    "    def fmt_time(tarr, i):\n",
    "        v = tarr.isel(time=i).values\n",
    "        try:\n",
    "            return np.datetime_as_string(np.asarray(v, dtype=\"datetime64[m]\"), unit='m')\n",
    "        except Exception:\n",
    "            try:\n",
    "                return v.strftime(\"%Y-%m-%d %H:%M\")\n",
    "            except Exception:\n",
    "                return str(v)\n",
    "\n",
    "    cmap = ListedColormap(colors)\n",
    "    norm = BoundaryNorm(boundaries=bounds, ncolors=cmap.N, extend='max')\n",
    "    cmap.set_bad(\"none\")\n",
    "\n",
    "    xname = next((c for c in (\"x\", \"lon\", \"longitude\") if c in var.coords), None)\n",
    "    yname = next((c for c in (\"y\", \"lat\", \"latitude\") if c in var.coords), None)\n",
    "    x = var[xname].values\n",
    "    y = var[yname].values\n",
    "\n",
    "    if y[0] > y[-1]:\n",
    "        extent = [x.min(), x.max(), y.max(), y.min()]\n",
    "        origin = \"upper\"\n",
    "    else:\n",
    "        extent = [x.min(), x.max(), y.min(), y.max()]\n",
    "        origin = \"lower\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 6), subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "    plt.close(fig)\n",
    "    ax.set_extent([x.min(), x.max(), y.min(), y.max()])\n",
    "    ax.coastlines(resolution='10m', color='black')\n",
    "    ax.add_feature(cfeature.BORDERS, edgecolor='black')\n",
    "\n",
    "    first_frame = var.isel(time=0).where(var.isel(time=0) > 0)\n",
    "    first_frame_flipped = np.ma.masked_invalid(first_frame.values[::-1, :]).astype(np.float32)\n",
    "\n",
    "    img = ax.imshow(\n",
    "        first_frame_flipped,\n",
    "        extent=extent,\n",
    "        origin=origin,\n",
    "        cmap=cmap,\n",
    "        norm=norm\n",
    "    )\n",
    "\n",
    "    cbar = fig.colorbar(img, ax=ax, fraction=0.05, pad=0.02, ticks=bounds)\n",
    "    cbar.set_label(\"Precipitation (mm/h)\")\n",
    "    ax.set_title(fmt_time(var[\"time\"], 0))\n",
    "\n",
    "    def update(i):\n",
    "        frame = var.isel(time=i).where(var.isel(time=i) > 0)\n",
    "        frame_flipped = np.ma.masked_invalid(frame.values[::-1, :]).astype(np.float32)\n",
    "        img.set_data(frame_flipped)\n",
    "        ax.set_title(fmt_time(var[\"time\"], i))\n",
    "        return (img,)\n",
    "\n",
    "    ani = FuncAnimation(fig, update, frames=var.sizes[\"time\"], interval=600, blit=True)\n",
    "\n",
    "    gif_filename = f\"nowcast_animation_{target_datetime.strftime('%Y%m%dT%H%M')}.gif\"\n",
    "    gif_path = time_folder / gif_filename\n",
    "    ani.save(gif_path, writer=\"pillow\", fps=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Excel file with observation time series\n",
    "if make_timeseries_Excel:\n",
    "    ds_obs = xr.open_mfdataset([str(f) for f in observations_input_nowcast])\n",
    "\n",
    "    last_time = ds_obs.time.values[-1]\n",
    "    last_time_str = np.datetime_as_string(last_time, unit='m')\n",
    "    safe_time_str = last_time_str.replace(\":\", \"\").replace(\"-\", \"\")\n",
    "\n",
    "    data_dict = {}\n",
    "    for pt in points_of_interest:\n",
    "        varname = \"precip_intensity\" if \"precip_intensity\" in ds_obs.data_vars else \"precipitation\"\n",
    "        rain_series = ds_obs.sel(\n",
    "            x=ds_obs[\"x\"].sel(x=pt[\"lon\"], method=\"nearest\"),\n",
    "            y=ds_obs[\"y\"].sel(y=pt[\"lat\"], method=\"nearest\")\n",
    "        )[varname]\n",
    "        data_dict[pt[\"name\"]] = rain_series.values\n",
    "\n",
    "    df_points = pd.DataFrame(data_dict, index=rain_series[\"time\"].values)\n",
    "    df_points.index.name = \"time\"\n",
    "\n",
    "    results_folder = Path(\"results\")\n",
    "    results_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Folder named by the time step\n",
    "    time_folder = results_folder / f\"ens_{ensemble_number}_{safe_time_str}\"\n",
    "    time_folder.mkdir(parents=True, exist_ok=True)\n",
    "    excel_filename = f\"observations_HSAF_points_timeseries_{safe_time_str}.xlsx\"\n",
    "    excel_path = time_folder / excel_filename\n",
    "    df_points.to_excel(excel_path, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Excel file with nowcast time series\n",
    "if make_timeseries_Excel:\n",
    "    nowcast_file = nowcasting_folder / \"pysteps_h60b_latest.nc\"\n",
    "    ds_nowcast = xr.open_dataset(nowcast_file)\n",
    "\n",
    "    varname = \"precip_intensity\" if \"precip_intensity\" in ds_nowcast.data_vars else \"precipitation\"\n",
    "    var = ds_nowcast[varname]\n",
    "    ds_nowcast.close()\n",
    "    if \"ens_number\" in var.dims:\n",
    "        var = var.isel(ens_number=ensemble_number)\n",
    "\n",
    "    data_dict = {}\n",
    "    y_vals = var[\"y\"].values\n",
    "    for pt in points_of_interest:\n",
    "        x_idx = abs(var[\"x\"].values - pt[\"lon\"]).argmin()\n",
    "        y_idx = abs(var[\"y\"].values - pt[\"lat\"]).argmin()\n",
    "        y_idx_flipped = len(y_vals) - 1 - y_idx  # flip Y-axis \n",
    "        rain_series = var[:, y_idx_flipped, x_idx]\n",
    "        data_dict[pt[\"name\"]] = rain_series.values\n",
    "\n",
    "    first_time = var.time.values[0]\n",
    "    first_time_str = np.datetime_as_string(first_time, unit='m')\n",
    "    safe_time_str = first_time_str.replace(\":\", \"\").replace(\"-\", \"\")\n",
    "\n",
    "    df_points = pd.DataFrame(data_dict, index=rain_series[\"time\"].values)\n",
    "    df_points.index.name = \"time\"\n",
    "    excel_filename = f\"nowcast_points_timeseries_{safe_time_str}.xlsx\"\n",
    "    excel_path = time_folder / excel_filename\n",
    "    df_points.to_excel(excel_path, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a plot with observation data\n",
    "if make_graph:\n",
    "    ds_obs = xr.open_mfdataset([str(f) for f in observations_input_nowcast])\n",
    "    varname = \"precip_intensity\" if \"precip_intensity\" in ds_obs.data_vars else \"precipitation\"\n",
    "    var = ds_obs[varname]\n",
    "\n",
    "    data_dict = {}\n",
    "    for pt in points_of_interest:\n",
    "        x_idx = abs(var[\"x\"].values - pt[\"lon\"]).argmin()\n",
    "        y_idx = abs(var[\"y\"].values - pt[\"lat\"]).argmin()\n",
    "        rain_series = var[:, y_idx, x_idx]\n",
    "        data_dict[pt[\"name\"]] = rain_series.values\n",
    "\n",
    "    df_points = pd.DataFrame(data_dict, index=var.time.values)\n",
    "    df_points.index.name = \"time\"\n",
    "\n",
    "    last_time_dt = pd.to_datetime(var.time.values[-1])\n",
    "    safe_time_str = last_time_dt.strftime(\"%Y%m%dT%H%M\")\n",
    "    results_folder = Path(\"results\")\n",
    "    time_folder = results_folder / f\"ens_{ensemble_number}_{safe_time_str}\"\n",
    "    time_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "    x = np.arange(len(df_points.index))\n",
    "    n_locations = len(df_points.columns)\n",
    "    width = 0.8 / n_locations\n",
    "\n",
    "    for i, col in enumerate(df_points.columns):\n",
    "        ax1.bar(\n",
    "            x + i * width,\n",
    "            df_points[col].values,\n",
    "            width=width,\n",
    "            label=col\n",
    "        )\n",
    "\n",
    "    ax1.set_xticks(x + width * (n_locations - 1) / 2)\n",
    "    ax1.set_xticklabels(pd.to_datetime(df_points.index).strftime(\"%Y-%m-%d %H:%M\"), rotation=45, ha=\"right\")\n",
    "    ax1.set_ylabel(\"Precipitation intensity (mm/h)\")\n",
    "    ax1.set_xlabel(\"Time\")\n",
    "\n",
    "    # Cumulative precipitation (multiply by 0.25 because time step = 15 min)\n",
    "    df_mm = df_points * 0.25\n",
    "    ax2 = ax1.twinx()\n",
    "    for col in df_mm.columns:\n",
    "        ax2.plot(\n",
    "            x,\n",
    "            df_mm[col].cumsum(),\n",
    "            linestyle=\"--\",\n",
    "            label=f\"Cumulative {col} (mm)\"\n",
    "        )\n",
    "    ax2.set_ylabel(\"Cumulative sum (mm)\")\n",
    "\n",
    "    lines_labels = [ax.get_legend_handles_labels() for ax in [ax1, ax2]]\n",
    "    lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "    ax1.legend(lines, labels, loc=\"upper left\")\n",
    "\n",
    "    plt.title(f\"Precipitation and cumulative sum\")\n",
    "    plt.tight_layout()\n",
    "    graph_filename = f\"observations_graph_{safe_time_str}.png\"\n",
    "    graph_path = time_folder / graph_filename\n",
    "    plt.savefig(graph_path, dpi=150)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a plot with nowcast data\n",
    "if make_graph:\n",
    "    nowcast_file = nowcasting_folder / \"pysteps_h60b_latest.nc\"\n",
    "    ds_nowcast = xr.open_dataset(nowcast_file)\n",
    "\n",
    "    varname = \"precip_intensity\" if \"precip_intensity\" in ds_nowcast.data_vars else \"precipitation\"\n",
    "    var = ds_nowcast[varname]\n",
    "    ds_nowcast.close()\n",
    "    if \"ens_number\" in var.dims:\n",
    "        var = var.isel(ens_number=ensemble_number)\n",
    "\n",
    "    first_time = var.time.values[0]\n",
    "    first_time_str = np.datetime_as_string(first_time, unit='m')\n",
    "    safe_time_str = first_time_str.replace(\":\", \"\").replace(\"-\", \"\")\n",
    "\n",
    "    data_dict = {}\n",
    "    y_vals = var[\"y\"].values\n",
    "    for pt in points_of_interest:\n",
    "        x_idx = abs(var[\"x\"].values - pt[\"lon\"]).argmin()\n",
    "        y_idx = abs(var[\"y\"].values - pt[\"lat\"]).argmin()\n",
    "        y_idx_flipped = len(y_vals) - 1 - y_idx  # Flip y-axis\n",
    "        rain_series = var[:, y_idx_flipped, x_idx]\n",
    "        data_dict[pt[\"name\"]] = rain_series.values\n",
    "\n",
    "    df_points = pd.DataFrame(data_dict, index=rain_series[\"time\"].values)\n",
    "    df_points.index.name = \"time\"\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "    x = np.arange(len(df_points.index))\n",
    "    width = 0.8 / len(df_points.columns)\n",
    "\n",
    "    for i, col in enumerate(df_points.columns):\n",
    "        ax1.bar(\n",
    "            x + i * width,\n",
    "            df_points[col].values,\n",
    "            width=width,\n",
    "            label=col\n",
    "        )\n",
    "\n",
    "    ax1.set_xticks(x + width * (len(df_points.columns)-1)/2)\n",
    "    ax1.set_xticklabels(df_points.index.strftime(\"%Y-%m-%d %H:%M\"), rotation=45, ha=\"right\")\n",
    "    ax1.set_ylabel(\"Precipitation intensity (mm/h)\")\n",
    "    ax1.set_xlabel(\"Time\")\n",
    "\n",
    "    # Convert to cumulative precipitation in mm (assuming 15 min timestep)\n",
    "    df_points_mm = df_points * 0.25\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    for col in df_points.columns:\n",
    "        ax2.plot(\n",
    "            x,\n",
    "            df_points_mm[col].cumsum(),\n",
    "            linestyle=\"--\",\n",
    "            label=f\"Cumulative {col} (mm)\"\n",
    "        )\n",
    "    ax2.set_ylabel(\"Cumulative sum (mm)\")\n",
    "\n",
    "    # Combine legends from both axes\n",
    "    lines_labels = [ax.get_legend_handles_labels() for ax in [ax1, ax2]]\n",
    "    lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "    ax1.legend(lines, labels, loc=\"upper left\")\n",
    "\n",
    "    plt.title(f\"Predicted precipitation intensity in Nowcast\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    graph_filename = f\"nowcast_graph_{safe_time_str}.png\"\n",
    "    graph_path = time_folder / graph_filename\n",
    "    plt.savefig(graph_path, dpi=150)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a combination GIF with the observed and nowcasted data \n",
    "\n",
    "if make_gif:\n",
    "    safe_time_str = target_datetime.strftime(\"%Y%m%dT%H%M\")\n",
    "    time_folder = results_folder / f\"ens_{ensemble_number}_{safe_time_str}\"\n",
    "    gif_files = list(time_folder.glob(\"*.gif\"))\n",
    "\n",
    "    obs_gif = next((f for f in gif_files if \"observations\" in f.name.lower()), None)\n",
    "    nowcast_gif = next((f for f in gif_files if \"nowcast\" in f.name.lower()), None)\n",
    "\n",
    "    def add_title(frame, title):\n",
    "        frame = frame.convert(\"RGBA\")\n",
    "        draw = ImageDraw.Draw(frame)\n",
    "        try:\n",
    "            font = ImageFont.truetype(\"arial.ttf\", 500)\n",
    "        except:\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "        text_bbox = draw.textbbox((0, 0), title, font=font)\n",
    "        text_width = text_bbox[2] - text_bbox[0]\n",
    "        x = (frame.width - text_width) // 2\n",
    "        y = 20\n",
    "\n",
    "        draw.text((x, y), title, fill=\"black\", font=font)\n",
    "        return frame\n",
    "\n",
    "    if obs_gif and nowcast_gif:\n",
    "        gif1 = Image.open(obs_gif)\n",
    "        gif2 = Image.open(nowcast_gif)\n",
    "\n",
    "        frames = []\n",
    "        for frame in ImageSequence.Iterator(gif1):\n",
    "            frames.append(add_title(frame.copy(), \"OBSERVATIONS\"))\n",
    "        for frame in ImageSequence.Iterator(gif2):\n",
    "            frames.append(add_title(frame.copy(), \"NOWCAST\"))\n",
    "\n",
    "        combination_path = time_folder / \"combined.gif\"\n",
    "        frames[0].save(\n",
    "            combination_path,\n",
    "            save_all=True,\n",
    "            append_images=frames[1:],\n",
    "            duration=600,\n",
    "            loop=0\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
