{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toutes les bibliothèques ont été importées avec succès!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import gzip\n",
    "import shutil\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta, date\n",
    "from ftplib import FTP\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import BoundaryNorm, ListedColormap\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import rioxarray\n",
    "from pyproj import CRS\n",
    "from pyresample.geometry import AreaDefinition\n",
    "try:\n",
    "    from satpy.readers.core._geos_area import get_area_extent\n",
    "except ImportError:\n",
    "    from satpy.readers._geos_area import get_area_extent\n",
    "from enhanced_steps import EnhancedStepsNowcast\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import gzip\n",
    "import shutil\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta, date\n",
    "from ftplib import FTP\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import BoundaryNorm, ListedColormap\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import rioxarray\n",
    "from pyproj import CRS\n",
    "from pyresample.geometry import AreaDefinition\n",
    "try:\n",
    "    from satpy.readers.core._geos_area import get_area_extent\n",
    "except ImportError:\n",
    "    from satpy.readers._geos_area import get_area_extent\n",
    "from enhanced_steps import EnhancedStepsNowcast\n",
    "from PIL import Image, ImageSequence, ImageDraw, ImageFont\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(\"Toutes les bibliothèques ont été importées avec succès!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"xxxxxxx\"                      # Remplacez par votre nom d'utilisateur réel\n",
    "password = \"xxxxxxx\"                # Remplacez par votre mot de passe réel\n",
    "\n",
    "# Mode de sélection : \"Selectionner_données_cibles\" ou \"Actuel\"\n",
    "selection_mode = \"Selectionner_données_cibles\"  \n",
    "# selection_mode = \"Actuel\"  \n",
    "\n",
    "target_datetime = datetime(2025, 7, 26, 15, 30)   # Point de départ pour la sélection des données\n",
    "n_steps = 10                                      # Nombre d'étapes à traiter\n",
    "region = {\"lat_min\": 4, \"lat_max\": 16, \"lon_min\": -6, \"lon_max\": 3}  # Région d'intérêt (latitude/longitude)\n",
    "ensemble_number = 1                              # Numéro du membre d'ensemble à utiliser\n",
    "\n",
    "points_dinteret = [\n",
    "    {\"nom\": \"Nouna\", \"lat\": 12.76, \"lon\": -3.84},        # Point d'intérêt 1\n",
    "    {\"nom\": \"Kante\", \"lat\": 9.961861, \"lon\": 1.042944},  # Point d'intérêt 2\n",
    "]\n",
    "\n",
    "make_gif = True                                 # True pour créer une animation GIF, False sinon\n",
    "make_timeseries_Excel = True                    # True pour générer un fichier Excel avec les séries temporelles\n",
    "make_graph = True                               # True pour créer des graphiques\n",
    "\n",
    "# Paramètres de visualisation\n",
    "bounds = [0, 0.5, 2, 5, 10, 15, 25, 40, 100]                      # Bornes pour la colorbar\n",
    "colors = [\"#ffffff\", \"#add8e6\", \"#0000ff\", \"#00ff00\",\n",
    "          \"#ffff00\", \"#ffa500\", \"#ff0000\", \"#ff69b4\", \"#ff69b4\"]  # Couleurs pour chaque intervalle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer des dossiers pour nos données\n",
    "data_folder = Path(\"./h60b_data\")\n",
    "raw_folder = data_folder / \"raw\"\n",
    "processed_folder = data_folder / \"processed\"\n",
    "nowcasting_folder = data_folder / \"nowcast\"\n",
    "\n",
    "# Créer les répertoires s'ils n'existent pas encore\n",
    "raw_folder.mkdir(parents=True, exist_ok=True)\n",
    "processed_folder.mkdir(parents=True, exist_ok=True)\n",
    "Path(nowcasting_folder).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connexion au serveur FTP HSAF...\n",
      "Connexion réussie!\n",
      "Dernier fichier disponible : h60_20250905_0800_fdk.nc.gz (2025-09-05 08:00:00)\n"
     ]
    }
   ],
   "source": [
    "# Détails du serveur FTP HSAF\n",
    "ftp_server = \"ftphsaf.meteoam.it\"\n",
    "ftp_directory = \"./h60B/h60_cur_mon_data/\"\n",
    "\n",
    "def parse_h60b_timestamp(filename):\n",
    "    try:\n",
    "        parts = filename.split(\"_\")\n",
    "        date_str = parts[1]                  # YYYYMMDD\n",
    "        time_str = parts[2].split(\".\")[0]    # HHMM\n",
    "        timestamp = datetime.strptime(f\"{date_str}{time_str}\", \"%Y%m%d%H%M\")\n",
    "        return timestamp\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def list_h60b_files_full():\n",
    "    try:\n",
    "        print(\"Connexion au serveur FTP HSAF...\")\n",
    "        with FTP(ftp_server) as ftp:\n",
    "            # Se connecter avec les identifiants\n",
    "            ftp.login(username, password)\n",
    "            print(\"Connexion réussie!\")\n",
    "            ftp.cwd(ftp_directory)\n",
    "            files = []\n",
    "            ftp.dir(lambda line: files.append(line.split()[-1]))\n",
    "            h60b_files = [f for f in files if f.startswith(\"h60\")]\n",
    "            timestamps_files = [(parse_h60b_timestamp(f), f) \n",
    "                                for f in h60b_files \n",
    "                                if parse_h60b_timestamp(f) is not None]\n",
    "            \n",
    "            if not timestamps_files:\n",
    "                print(\"Aucun fichier avec timestamp valide trouvé.\")\n",
    "                return []\n",
    "            \n",
    "            timestamps_files.sort()\n",
    "            \n",
    "            first_file = timestamps_files[0]\n",
    "            last_file  = timestamps_files[-1]\n",
    "            print(f\"Dernier fichier disponible : {last_file[1]} ({last_file[0]})\")\n",
    "            return [f[1] for f in timestamps_files]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la connexion FTP : {e}\")\n",
    "        print(\"Assurez-vous de vous être inscrit sur https://hsaf.meteoam.it/ et d'avoir des identifiants valides\")\n",
    "        return []\n",
    "    \n",
    "all_files = list_h60b_files_full()\n",
    "timestamps_files = [(parse_h60b_timestamp(f), f) for f in all_files if parse_h60b_timestamp(f)]\n",
    "timestamps_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_files_before_date(target_time=None, n_steps=10, timestamps_files=timestamps_files, actuel=False):\n",
    "    if not timestamps_files:\n",
    "        print(\"Aucun fichier disponible pour la sélection.\")\n",
    "        return []\n",
    "\n",
    "    if actuel:\n",
    "        selectionnes = timestamps_files[-n_steps:] if n_steps <= len(timestamps_files) else timestamps_files\n",
    "        return [f[1] for f in selectionnes]\n",
    "\n",
    "    if target_time is None:\n",
    "        print(\"Erreur : target_time doit être fourni si 'actuel' est False.\")\n",
    "        return []\n",
    "\n",
    "    fichiers_selectionnes = []\n",
    "    ts_courant = target_time\n",
    "\n",
    "    for _ in range(n_steps):\n",
    "        fichier_precedent = None\n",
    "        for ts, f in reversed(timestamps_files):\n",
    "            if ts <= ts_courant:\n",
    "                fichier_precedent = (ts, f)\n",
    "                break\n",
    "\n",
    "        if fichier_precedent:\n",
    "            fichiers_selectionnes.append(fichier_precedent[1])\n",
    "            ts_courant = fichier_precedent[0] - timedelta(minutes=15)\n",
    "        else:\n",
    "            print(f\"Aucun fichier disponible avant {ts_courant}\")\n",
    "            break\n",
    "\n",
    "    return fichiers_selectionnes[::-1]\n",
    "\n",
    "if selection_mode == \"Selectionner_données_cibles\":\n",
    "    selected_files = select_files_before_date(target_datetime, n_steps=n_steps, actuel=False)\n",
    "elif selection_mode == \"Actuel\":\n",
    "    selected_files = select_files_before_date(target_datetime, n_steps=n_steps, actuel=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_h60b_file(filename, output_folder=None):\n",
    "\n",
    "    target_folder = Path(output_folder) if output_folder else raw_folder\n",
    "    target_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    gz_path = target_folder / filename\n",
    "    nc_path = target_folder / filename.replace(\".gz\", \"\")\n",
    "\n",
    "    if nc_path.exists():\n",
    "        print(f\"Le fichier existe déjà : {nc_path.name}\")\n",
    "        return str(nc_path)\n",
    "\n",
    "    try:\n",
    "        print(f\"Téléchargement de {filename}...\")\n",
    "\n",
    "        with FTP(ftp_server) as ftp:\n",
    "            ftp.login(username, password)\n",
    "            ftp.cwd(ftp_directory)\n",
    "\n",
    "            with open(gz_path, \"wb\") as f:\n",
    "                ftp.retrbinary(f\"RETR {filename}\", f.write)\n",
    "\n",
    "        file_size = gz_path.stat().st_size / (1024*1024)  # Taille en MB\n",
    "        with gzip.open(gz_path, \"rb\") as f_in:\n",
    "            with open(nc_path, \"wb\") as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        gz_path.unlink()\n",
    "\n",
    "        final_size = nc_path.stat().st_size / (1024*1024)  # Taille finale en MB\n",
    "\n",
    "        return str(nc_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du téléchargement de {filename} : {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_file(raw_file: str, output_folder=None):\n",
    "    \n",
    "    target_folder = Path(output_folder) if output_folder else processed_folder\n",
    "    target_folder.mkdir(parents=True, exist_ok=True)\n",
    "    filename = Path(raw_file).name\n",
    "\n",
    "    # Extraire le timestamp depuis le nom du fichier et définir le chemin de sortie\n",
    "    timestamp = parse_h60b_timestamp(filename)\n",
    "    hsaf_filename = f\"HSAF-H60B_{timestamp.strftime('%Y%m%dT%H%M%S')}.nc\"\n",
    "    output_path_HSAF = target_folder / hsaf_filename\n",
    "\n",
    "    # Vérifier si le fichier prétraité existe déjà\n",
    "    if output_path_HSAF.exists():\n",
    "        print(f\"Fichier déjà prétraité : {hsaf_filename} -> Ignorer le prétraitement\")\n",
    "        return str(output_path_HSAF)\n",
    "\n",
    "    # --- Définitions des systèmes de coordonnées\n",
    "    crs_in = \"+proj=geos +a=6378.169 +b=6356.584 +h=35785.831 +lat_0=0 +lon_0=0.000000\"  # CRS d’origine (satellite)\n",
    "    crs_out = \"EPSG:4326\"  # CRS de sortie : latitude/longitude\n",
    "\n",
    "    ds = xr.open_dataset(raw_file, decode_coords=\"all\", decode_cf=False)\n",
    "    ds = ds.rename({\"nx\": \"x\", \"ny\": \"y\"})\n",
    "    rr_raw = ds[\"rr\"]\n",
    "    scale_factor = rr_raw.encoding.get(\"scale_factor\", 0.1)\n",
    "    add_offset  = rr_raw.encoding.get(\"add_offset\", 0.0)\n",
    "    ds[\"rr\"] = rr_raw.astype(\"float32\") * scale_factor + add_offset\n",
    "    ds[\"rr\"].encoding.clear()\n",
    "    ds[\"rr\"].attrs.clear()\n",
    "    ds = ds[[\"rr\"]].astype(\"float32\")\n",
    "\n",
    "    source_crs = CRS.from_proj4(ds.attrs[\"gdal_projection\"])\n",
    "    crs_in = source_crs.to_proj4()  # CRS exact du fichier\n",
    "    crs_out = \"EPSG:4326\"\n",
    "    cgms_projection = (\n",
    "        \"+proj=geos +coff=1856.000000 +cfac=13642337.000000 \"\n",
    "        \"+loff=1856.000000 +lfac=13642337.000000 \"\n",
    "        \"+spp=0.000000 +r_eq=6378.169000 +r_pol=6356.583800 +h=42164.000000\"\n",
    "    )\n",
    "    matches = re.findall(r\"\\+?(\\w+)\\s*=\\s*([^\\s]+)\", cgms_projection)\n",
    "    parse_dict = {k: v for k, v in matches}\n",
    "    cd = source_crs.to_dict()\n",
    "    area_extent = get_area_extent({\n",
    "        \"scandir\": \"N2S\",                                                           # scandir : direction de balayage du satellite (N2S = Nord vers Sud)\n",
    "        \"h\": float(parse_dict[\"h\"]) * 1000 - float(parse_dict[\"r_eq\"]) * 1000,      # h : hauteur du satellite au-dessus de la Terre       \n",
    "        \"loff\": float(parse_dict[\"loff\"]),                                          # loff, coff : décalages de ligne et de colonne (début du raster)\n",
    "        \"coff\": float(parse_dict[\"coff\"]),                                          \n",
    "        \"lfac\": float(parse_dict[\"lfac\"]),                                          # lfac, cfac : facteurs d'échelle pour les lignes et colonnes\n",
    "        \"cfac\": float(parse_dict[\"cfac\"]),\n",
    "        \"ncols\": ds.x.size,                                                         # ncols, nlines : nombre de colonnes et lignes du raster\n",
    "        \"nlines\": ds.y.size,\n",
    "    })\n",
    "\n",
    "    area_def_src = AreaDefinition(\n",
    "        \"areaD\",\n",
    "        cd[\"proj\"],\n",
    "        \"areaD\",\n",
    "        {\"lon_0\": cd[\"lon_0\"], \"a\": cd[\"a\"], \"b\": cd[\"b\"], \"h\": cd[\"h\"], \"proj\": cd[\"proj\"]},\n",
    "        ds.y.size,\n",
    "        ds.x.size,\n",
    "        (area_extent[0], area_extent[1], area_extent[2], area_extent[3]),\n",
    "    )\n",
    "\n",
    "    # Créer de nouvelles coordonnées X et Y\n",
    "    x, y = area_def_src.get_proj_coords()\n",
    "    new_x_coords = np.linspace(x.min(), x.max(), num=ds.sizes[\"x\"])\n",
    "    new_y_coords = np.linspace(y.max(), y.min(), num=ds.sizes[\"y\"])\n",
    "    ds = ds.assign_coords(y=(\"y\", new_y_coords), x=(\"x\", new_x_coords))\n",
    "\n",
    "    # Écrire le CRS qui correspond aux unités des coordonnées\n",
    "    ds = ds.rio.write_crs(crs_in)\n",
    "    ds = ds.rename({\"rr\": \"precip_intensity\"}).sortby(\"y\")\n",
    "    ds = ds.expand_dims(\"time\").assign_coords(time=(\"time\", [timestamp]))\n",
    "    ds = ds.transpose(\"time\", \"y\", \"x\")\n",
    "    ds.precip_intensity.attrs = {\n",
    "        \"standard_name\": \"precipitation_flux\",\n",
    "        \"long_name\": \"Flux de précipitation dérivé des propriétés optiques des nuages\",\n",
    "        \"units\": \"kg m-2 h-1\",\n",
    "    }\n",
    "\n",
    "    ds[\"precip_intensity\"] = ds[\"precip_intensity\"].where(ds[\"precip_intensity\"] >= 0, np.nan)\n",
    "    da = ds[\"precip_intensity\"].rio.write_nodata(np.nan, encoded=True)\n",
    "    ds[\"precip_intensity\"] = da\n",
    "    ds = ds.rio.reproject(crs_out, nodata=np.nan)\n",
    "\n",
    "    # Nettoyer l'encodage après reprojection\n",
    "    for var_name in ds.data_vars:\n",
    "        ds[var_name].encoding.clear()\n",
    "        for attr in [\"_FillValue\", \"missing_value\", \"fill_value\", \"FillValue\"]:\n",
    "            ds[var_name].attrs.pop(attr, None)\n",
    "\n",
    "    # Ordre final des dimensions\n",
    "    ds = ds.transpose(\"time\", \"y\", \"x\")\n",
    "\n",
    "    # Définir les attributs CF pour les coordonnées\n",
    "    ds.x.attrs = {\"standard_name\": \"longitude\", \"long_name\": \"longitude\", \"units\": \"degrees_east\", \"axis\": \"X\"}\n",
    "    ds.y.attrs = {\"standard_name\": \"latitude\", \"long_name\": \"latitude\", \"units\": \"degrees_north\", \"axis\": \"Y\"}\n",
    "    ds.time.attrs = {\"standard_name\": \"time\", \"long_name\": \"time\", \"axis\": \"T\"}\n",
    "\n",
    "    # Définir les attributs globaux du dataset\n",
    "    ds.attrs = {\n",
    "        \"Conventions\": \"CF-1.6\",\n",
    "        \"title\": \"RAINSAT H60B MSG SEVIRI Precipitation\",\n",
    "        \"source\": \"EUMETSAT H-SAF H60B\",\n",
    "        \"creator\": \"HKV services\",\n",
    "        \"creation_date\": date.today().strftime(\"%Y-%m-%d\"),\n",
    "        \"time_coverage_start\": timestamp.strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
    "        \"time_coverage_end\": (timestamp + timedelta(minutes=15)).strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
    "        \"geospatial_lat_min\": float(ds.y.min()),\n",
    "        \"geospatial_lat_max\": float(ds.y.max()),\n",
    "        \"geospatial_lon_min\": float(ds.x.min()),\n",
    "        \"geospatial_lon_max\": float(ds.x.max()),\n",
    "        \"crs\": crs_out,\n",
    "        \"product_details\": \"https://hsaf.meteoam.it/Products/Detail?prod=H60B\",\n",
    "        \"data_source\": \"hsaf-h60b\",\n",
    "    }\n",
    "\n",
    "    # Encodage pour NetCDF\n",
    "    encoding = {\n",
    "        \"precip_intensity\": {\"dtype\": \"float32\", \"zlib\": True, \"complevel\": 4, \"_FillValue\": -999.0},\n",
    "        \"time\": {\"units\": \"minutes since 1970-01-01 00:00:00\", \"dtype\": \"float64\"},\n",
    "    }\n",
    "\n",
    "    # Sauvegarder le fichier NetCDF prétraité\n",
    "    ds.to_netcdf(output_path_HSAF, encoding=encoding)\n",
    "    ds.close()\n",
    "    print(f\"Fichier H60B prétraité avec succès : {hsaf_filename}\")\n",
    "    return str(output_path_HSAF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier existe déjà : h60_20250726_1315_fdk.nc\n",
      "HSAF-H60B_20250726T131500.nc existe déjà, passage au fichier suivant\n",
      "----------------------------------------\n",
      "Le fichier existe déjà : h60_20250726_1330_fdk.nc\n",
      "HSAF-H60B_20250726T133000.nc existe déjà, passage au fichier suivant\n",
      "----------------------------------------\n",
      "Le fichier existe déjà : h60_20250726_1345_fdk.nc\n",
      "HSAF-H60B_20250726T134500.nc existe déjà, passage au fichier suivant\n",
      "----------------------------------------\n",
      "Le fichier existe déjà : h60_20250726_1400_fdk.nc\n",
      "HSAF-H60B_20250726T140000.nc existe déjà, passage au fichier suivant\n",
      "----------------------------------------\n",
      "Le fichier existe déjà : h60_20250726_1415_fdk.nc\n",
      "HSAF-H60B_20250726T141500.nc existe déjà, passage au fichier suivant\n",
      "----------------------------------------\n",
      "Le fichier existe déjà : h60_20250726_1430_fdk.nc\n",
      "HSAF-H60B_20250726T143000.nc existe déjà, passage au fichier suivant\n",
      "----------------------------------------\n",
      "Le fichier existe déjà : h60_20250726_1445_fdk.nc\n",
      "HSAF-H60B_20250726T144500.nc existe déjà, passage au fichier suivant\n",
      "----------------------------------------\n",
      "Le fichier existe déjà : h60_20250726_1500_fdk.nc\n",
      "HSAF-H60B_20250726T150000.nc existe déjà, passage au fichier suivant\n",
      "----------------------------------------\n",
      "Le fichier existe déjà : h60_20250726_1515_fdk.nc\n",
      "HSAF-H60B_20250726T151500.nc existe déjà, passage au fichier suivant\n",
      "----------------------------------------\n",
      "Le fichier existe déjà : h60_20250726_1530_fdk.nc\n",
      "HSAF-H60B_20250726T153000.nc existe déjà, passage au fichier suivant\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Boucle finale pour télécharger et prétraiter les fichiers sélectionnés\n",
    "for selected_file in selected_files:\n",
    "    downloaded_file = download_h60b_file(selected_file)\n",
    "    timestamp = parse_h60b_timestamp(Path(downloaded_file).name)\n",
    "    hsaf_filename = f\"HSAF-H60B_{timestamp.strftime('%Y%m%dT%H%M%S')}.nc\"\n",
    "    output_path_HSAF = processed_folder / hsaf_filename\n",
    "\n",
    "    if output_path_HSAF.exists():\n",
    "        print(f\"{hsaf_filename} existe déjà, passage au fichier suivant\\n\" + \"-\"*40)\n",
    "        continue\n",
    "    \n",
    "    preprocess_file(downloaded_file)\n",
    "    print(f\"{selected_file} traité\\n\" + \"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"data_source\": \"h60b\",     # Source des données\n",
    "    \"ensemble\": 5,             # Nombre de membres de l'ensemble\n",
    "    \"n_input_files\": 10,       # Nombre de fichiers d'entrée utilisés\n",
    "    \"n_lead_times\": 12,        # Nombre de pas de temps à prévoir, chaque pas de temps dure 15 minutes\n",
    "    \"frequency\": 15,           # Minutes entre chaque pas de temps\n",
    "    \"transform\": \"dB\",         # Transformation utilisée par pysteps (\"dB\", \"log\", ...)\n",
    "    \"threshold\": 0.05,         # Seuil (mm/h) pour définir pluie / pas de pluie\n",
    "    \"buffer_distance\": 5000,    # Distance en mètres autour du pays pour le découpage\n",
    "    \"crs_out\": \"EPSG:4326\",    # Système de coordonnées de sortie\n",
    "    \"norain_thr\": 0.005,       # Paramètres pour la méthode Norain\n",
    "    \"zerovalue\": -15.0,        # Paramètres pour la méthode Norain\n",
    "    \"max_workers\": 2,          # Nombre de processeurs à utiliser\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_files_by_timestamp(selected_files, processed_folder):\n",
    "    processed_folder = Path(processed_folder)\n",
    "    all_files = list(processed_folder.glob(\"*\"))\n",
    "\n",
    "    ts_list = []\n",
    "    pattern_selected = r\"(\\d{8}_\\d{4})\"\n",
    "    for f in selected_files:\n",
    "        match = re.search(pattern_selected, f)\n",
    "        if match:\n",
    "            dt = datetime.strptime(match.group(), \"%Y%m%d_%H%M\")\n",
    "            ts_list.append(dt)\n",
    "\n",
    "    matched_files = []\n",
    "    pattern_processed = r\"(\\d{8}T\\d{6})\"  \n",
    "    for f in all_files:\n",
    "        match = re.search(pattern_processed, f.name)\n",
    "        if match:\n",
    "            dt_f = datetime.strptime(match.group(), \"%Y%m%dT%H%M%S\")\n",
    "            if dt_f in ts_list:\n",
    "                matched_files.append(f)\n",
    "\n",
    "    matched_files.sort(key=lambda x: re.search(pattern_processed, x.name).group())\n",
    "    return matched_files\n",
    "\n",
    "observations_input_nowcast = match_files_by_timestamp(selected_files, processed_folder)\n",
    "\n",
    "def open_as_time_stack(input_files):\n",
    "    if not input_files:\n",
    "        raise FileNotFoundError(\"Aucun fichier d'entrée trouvé.\")   \n",
    "    datasets = xr.open_mfdataset(input_files)                       \n",
    "    return datasets\n",
    "\n",
    "input_dataset = open_as_time_stack(observations_input_nowcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rain fraction is: 0.12485211895308322, while minimum fraction is 0.005\n",
      "unknown projection longlat\n",
      "Inputs validated and initialized successfully.\n",
      "Computing STEPS nowcast\n",
      "-----------------------\n",
      "\n",
      "Inputs\n",
      "------\n",
      "input dimensions: 287x215\n",
      "km/pixel:         3.0\n",
      "time step:        15 minutes\n",
      "\n",
      "Methods\n",
      "-------\n",
      "extrapolation:          semilagrangian\n",
      "bandpass filter:        gaussian\n",
      "decomposition:          fft\n",
      "noise generator:        nonparametric\n",
      "noise adjustment:       no\n",
      "velocity perturbator:   None\n",
      "conditional statistics: no\n",
      "precip. mask method:    incremental\n",
      "probability matching:   cdf\n",
      "FFT method:             numpy\n",
      "domain:                 spatial\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "number of time steps:     12\n",
      "ensemble size:            5\n",
      "parallel threads:         2\n",
      "number of cascade levels: 6\n",
      "order of the AR(p) model: 2\n",
      "precip. intensity threshold: -13.010299956639813\n",
      "Nowcast components initialized successfully.\n",
      "Rain fraction is: 0.11410744672230776, while minimum fraction is 0.0\n",
      "Extrapolation complete and precipitation fields aligned.\n",
      "************************************************\n",
      "* Correlation coefficients for cascade levels: *\n",
      "************************************************\n",
      "-----------------------------------------\n",
      "| Level |     Lag-1     |     Lag-2     |\n",
      "-----------------------------------------\n",
      "| 1     | 0.991360      | 0.983263      |\n",
      "-----------------------------------------\n",
      "| 2     | 0.983777      | 0.968706      |\n",
      "-----------------------------------------\n",
      "| 3     | 0.938818      | 0.883962      |\n",
      "-----------------------------------------\n",
      "| 4     | 0.786482      | 0.632696      |\n",
      "-----------------------------------------\n",
      "| 5     | 0.351279      | 0.131858      |\n",
      "-----------------------------------------\n",
      "| 6     | 0.118296      | 0.088390      |\n",
      "-----------------------------------------\n",
      "****************************************\n",
      "* AR(p) parameters for cascade levels: *\n",
      "****************************************\n",
      "------------------------------------------------------\n",
      "| Level |    Phi-1     |    Phi-2     |    Phi-0     |\n",
      "------------------------------------------------------\n",
      "| 1     | 0.964357     | 0.027238     | 0.131123     |\n",
      "------------------------------------------------------\n",
      "| 2     | 0.956588     | 0.027637     | 0.179329     |\n",
      "------------------------------------------------------\n",
      "| 3     | 0.918375     | 0.021775     | 0.344332     |\n",
      "------------------------------------------------------\n",
      "| 4     | 0.757324     | 0.037074     | 0.617188     |\n",
      "------------------------------------------------------\n",
      "| 5     | 0.347888     | 0.009653     | 0.936227     |\n",
      "------------------------------------------------------\n",
      "| 6     | 0.109370     | 0.075452     | 0.990148     |\n",
      "------------------------------------------------------\n",
      "AR model and noise applied to precipitation cascades.\n",
      "Velocity perturbations initialized successfully.\n",
      "Precipitation mask initialized successfully.\n",
      "FFT objects initialized successfully.\n",
      "Starting nowcast computation.\n",
      "Computing nowcast for time step 1... done.\n",
      "Computing nowcast for time step 2... done.\n",
      "Computing nowcast for time step 3... done.\n",
      "Computing nowcast for time step 4... done.\n",
      "Computing nowcast for time step 5... done.\n",
      "Computing nowcast for time step 6... done.\n",
      "Computing nowcast for time step 7... done.\n",
      "Computing nowcast for time step 8... done.\n",
      "Computing nowcast for time step 9... done.\n",
      "Computing nowcast for time step 10... done.\n",
      "Computing nowcast for time step 11... done.\n",
      "Computing nowcast for time step 12... done.\n"
     ]
    }
   ],
   "source": [
    "nc_path = Path(\"h60b_data/nowcast/pysteps_h60b_latest.nc\")\n",
    "if nc_path.exists():\n",
    "    nc_path.unlink()\n",
    "\n",
    "steps_settings = {\n",
    "    \"datafolder\": data_folder,                      # Dossier contenant les fichiers HSAF prétraités\n",
    "    \"ensemble\": settings[\"ensemble\"],               # Nombre de membres de l'ensemble\n",
    "    \"n_lead_times\": settings[\"n_lead_times\"],       # Nombre de pas de temps à prévoir\n",
    "    \"frequency\": settings[\"frequency\"],             # Fréquence entre chaque pas de temps (minutes)\n",
    "    \"transform\": settings[\"transform\"],             # Transformation PySTEPS (\"dB\", \"log\", etc.)\n",
    "    \"threshold\": settings[\"threshold\"],             # Seuil pour distinguer pluie / pas de pluie\n",
    "    \"buffer_distance\": settings[\"buffer_distance\"], # Tampon autour de la zone d'intérêt\n",
    "    \"crs_out\": settings[\"crs_out\"],                 # Système de coordonnées de sortie\n",
    "    \"norain_thr\": settings[\"norain_thr\"],           # Paramètre pour \"no rain\"\n",
    "    \"zerovalue\": settings[\"zerovalue\"],             # Valeur minimale pour \"no rain\"\n",
    "    \"max_workers\": settings[\"max_workers\"],         # Nombre de CPU à utiliser\n",
    "}\n",
    "\n",
    "engine = EnhancedStepsNowcast(steps_settings, \"h60b\")\n",
    "\n",
    "dataset_roi = input_dataset.sel(\n",
    "    x=slice(region[\"lon_min\"], region[\"lon_max\"]),\n",
    "    y=slice(region[\"lat_max\"], region[\"lat_min\"])  # attention aux coordonnées inversées\n",
    ")\n",
    "\n",
    "nowcast_arrays, metadata = engine.nowcast_steps_pysteps(dataset_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_nowcast = \"/workspaces/Tools-for-weather-and-climate-services-in-Africa/2_Créer_un_Nowcast_avec_HSAF_H60B/h60b_data/nowcast\"\n",
    "Path(output_path_nowcast).mkdir(parents=True, exist_ok=True)\n",
    "engine.settings[\"threddsdata\"] = output_path_nowcast   \n",
    "country_name = f\"Togo_BurkinaFaso_{target_datetime.strftime('%Y%m%dT%H%M')}\"\n",
    "\n",
    "engine.export_nowcast_to_netcdf(\n",
    "    country=country_name,\n",
    "    nowcasting_arrays=nowcast_arrays,\n",
    "    date_start=None,  \n",
    "    metadata=metadata,\n",
    "    reproject=True,\n",
    "    data_source=settings[\"data_source\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options de sauvegarde des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créez des GIF pour les observations \n",
    "if make_gif:\n",
    "    obs_files = []\n",
    "    pattern = r\"\\d{8}T\\d{4}\"  \n",
    "\n",
    "    for f in observations_input_nowcast:\n",
    "        match = re.search(pattern, str(f))  \n",
    "        if match:\n",
    "            ts_str = match.group()\n",
    "            matching = list(processed_folder.glob(f\"*{ts_str}*.nc\"))\n",
    "            obs_files.extend(matching)\n",
    "        else:\n",
    "            print(f\"Geen timestamp gevonden in: {f}\")\n",
    "\n",
    "    if not obs_files:\n",
    "        print(\"Geen observatiebestanden gevonden voor de geselecteerde tijdstappen.\")\n",
    "    else:\n",
    "        ds_obs = xr.open_mfdataset([str(f) for f in obs_files])\n",
    "\n",
    "        # Region of Interest\n",
    "        ds_roi = ds_obs.sel(\n",
    "            x=slice(region[\"lon_min\"], region[\"lon_max\"]),\n",
    "            y=slice(region[\"lat_max\"], region[\"lat_min\"])\n",
    "        )\n",
    "\n",
    "        var = ds_roi[\"precip_intensity\"] if \"precip_intensity\" in ds_roi.data_vars else ds_roi[\"precipitation\"]\n",
    "        x = var[\"x\"].values\n",
    "        y = var[\"y\"].values\n",
    "\n",
    "        if y[0] > y[-1]:\n",
    "            extent = [x.min(), x.max(), y.max(), y.min()]\n",
    "            origin = \"upper\"\n",
    "        else:\n",
    "            extent = [x.min(), x.max(), y.min(), y.max()]\n",
    "            origin = \"lower\"\n",
    "\n",
    "        cmap = ListedColormap(colors)\n",
    "        norm = BoundaryNorm(boundaries=bounds, ncolors=cmap.N, extend='max')\n",
    "        cmap.set_bad(\"none\")\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(5, 6), subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "        plt.close(fig)\n",
    "        ax.set_extent([x.min(), x.max(), y.min(), y.max()])\n",
    "        ax.coastlines(resolution='10m', color='black')\n",
    "        ax.add_feature(cfeature.BORDERS, edgecolor='black')\n",
    "\n",
    "        last_frame = var.isel(time=-1)\n",
    "        last_frame_flipped = np.ma.masked_invalid(last_frame.values[::-1, :]).astype(np.float32)\n",
    "\n",
    "        img = ax.imshow(\n",
    "            last_frame_flipped,\n",
    "            extent=extent,\n",
    "            origin=origin,\n",
    "            cmap=cmap,\n",
    "            norm=norm\n",
    "        )\n",
    "\n",
    "        cbar = fig.colorbar(img, ax=ax, fraction=0.05, pad=0.02, ticks=bounds)\n",
    "        cbar.set_label(\"Précipitations (mm/h)\")\n",
    "        ax.set_title(np.datetime_as_string(last_frame.time.values, unit='m'))\n",
    "        def update(i):\n",
    "            frame = var.isel(time=i)\n",
    "            frame_flipped = np.ma.masked_invalid(frame.values[::-1, :]).astype(np.float32)\n",
    "            img.set_data(frame_flipped)\n",
    "            ax.set_title(np.datetime_as_string(frame.time.values, unit='m'))\n",
    "            return (img,)\n",
    "\n",
    "        ani = FuncAnimation(fig, update, frames=var.sizes[\"time\"], interval=600, blit=True)\n",
    "\n",
    "        results_folder = Path(\"results\")\n",
    "        results_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        last_time = var.time.values[9]\n",
    "        last_time_dt = pd.to_datetime(last_time)\n",
    "        safe_time_str = last_time_dt.strftime(\"%Y%m%dT%H%M\")\n",
    "\n",
    "        time_folder = results_folder / f\"ens_{ensemble_number}_{safe_time_str}\"\n",
    "        time_folder.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        gif_filename = f\"observations_animation_{safe_time_str}.gif\"\n",
    "        gif_path = time_folder / gif_filename\n",
    "        ani.save(gif_path, writer=\"pillow\", fps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créez des GIF pour le nowcast \n",
    "if make_gif:\n",
    "    ds_nowcast = xr.open_dataset(nowcasting_folder / \"pysteps_h60b_latest.nc\")\n",
    "    varname = \"precip_intensity\" if \"precip_intensity\" in ds_nowcast.data_vars else \"precipitation\"\n",
    "    var = ds_nowcast[varname]\n",
    "    ds_nowcast.close()\n",
    "    if \"ens_number\" in var.dims:\n",
    "        var = var.isel(ens_number=ensemble_number)\n",
    "\n",
    "    def fmt_time(tarr, i):\n",
    "        v = tarr.isel(time=i).values\n",
    "        try:\n",
    "            return np.datetime_as_string(np.asarray(v, dtype=\"datetime64[m]\"), unit='m')\n",
    "        except Exception:\n",
    "            try:\n",
    "                return v.strftime(\"%Y-%m-%d %H:%M\")\n",
    "            except Exception:\n",
    "                return str(v)\n",
    "\n",
    "    cmap = ListedColormap(colors)\n",
    "    norm = BoundaryNorm(boundaries=bounds, ncolors=cmap.N, extend='max')\n",
    "    cmap.set_bad(\"none\")\n",
    "    xname = next((c for c in (\"x\", \"lon\", \"longitude\") if c in var.coords), None)\n",
    "    yname = next((c for c in (\"y\", \"lat\", \"latitude\") if c in var.coords), None)\n",
    "    x = var[xname].values\n",
    "    y = var[yname].values\n",
    "\n",
    "    if y[0] > y[-1]:\n",
    "        extent = [x.min(), x.max(), y.max(), y.min()]\n",
    "        origin = \"upper\"\n",
    "    else:\n",
    "        extent = [x.min(), x.max(), y.min(), y.max()]\n",
    "        origin = \"lower\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 6), subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "    plt.close(fig) \n",
    "    ax.set_extent([x.min(), x.max(), y.min(), y.max()])\n",
    "    ax.coastlines(resolution='10m', color='black')\n",
    "    ax.add_feature(cfeature.BORDERS, edgecolor='black')\n",
    "\n",
    "    first_frame = var.isel(time=0).where(var.isel(time=0) > 0)\n",
    "    first_frame_flipped = np.ma.masked_invalid(first_frame.values[::-1, :]).astype(np.float32)\n",
    "\n",
    "    img = ax.imshow(\n",
    "        first_frame_flipped,\n",
    "        extent=extent,\n",
    "        origin=origin,\n",
    "        cmap=cmap,\n",
    "        norm=norm\n",
    "    )\n",
    "\n",
    "    cbar = fig.colorbar(img, ax=ax, fraction=0.05, pad=0.02, ticks=bounds)\n",
    "    cbar.set_label(\"Précipitations (mm/h)\")\n",
    "    ax.set_title(fmt_time(var[\"time\"], 0))\n",
    "\n",
    "    def update(i):\n",
    "        frame = var.isel(time=i).where(var.isel(time=i) > 0)\n",
    "        frame_flipped = np.ma.masked_invalid(frame.values[::-1, :]).astype(np.float32)\n",
    "        img.set_data(frame_flipped)\n",
    "        ax.set_title(fmt_time(var[\"time\"], i))\n",
    "        return (img,)\n",
    "\n",
    "    ani = FuncAnimation(fig, update, frames=var.sizes[\"time\"], interval=600, blit=True)\n",
    "\n",
    "    gif_filename = f\"nowcast_animation_{target_datetime.strftime('%Y%m%dT%H%M')}.gif\"\n",
    "    gif_path = time_folder / gif_filename\n",
    "    ani.save(gif_path, writer=\"pillow\", fps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Créer Excel avec des observations de séries chronologiques\n",
    "if make_timeseries_Excel:\n",
    "    ds_obs = xr.open_mfdataset([str(f) for f in observations_input_nowcast])\n",
    "\n",
    "    last_time = ds_obs.time.values[-1]\n",
    "    last_time_str = np.datetime_as_string(last_time, unit='m')\n",
    "    safe_time_str = last_time_str.replace(\":\", \"\").replace(\"-\", \"\")\n",
    "\n",
    "    data_dict = {}\n",
    "    for pt in points_dinteret:\n",
    "        varname = \"precip_intensity\" if \"precip_intensity\" in ds_obs.data_vars else \"precipitation\"\n",
    "        rain_series = ds_obs.sel(\n",
    "            x=ds_obs[\"x\"].sel(x=pt[\"lon\"], method=\"nearest\"),\n",
    "            y=ds_obs[\"y\"].sel(y=pt[\"lat\"], method=\"nearest\")\n",
    "        )[varname]\n",
    "        data_dict[pt[\"nom\"]] = rain_series.values\n",
    "\n",
    "    df_points = pd.DataFrame(data_dict, index=rain_series[\"time\"].values)\n",
    "    df_points.index.name = \"time\"\n",
    "\n",
    "    results_folder = Path(\"results\")\n",
    "    results_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Folder met de tijdstap als naam\n",
    "    time_folder = results_folder / f\"ens_{ensemble_number}_{safe_time_str}\"\n",
    "    time_folder.mkdir(parents=True, exist_ok=True)\n",
    "    excel_filename = f\"observations_HSAF_points_timeseries_{safe_time_str}.xlsx\"\n",
    "    excel_path = time_folder / excel_filename\n",
    "    df_points.to_excel(excel_path, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Créer Excel avec du nowcast de séries chronologiques\n",
    "if make_timeseries_Excel:\n",
    "    nowcast_file = nowcasting_folder / \"pysteps_h60b_latest.nc\"\n",
    "    ds_nowcast = xr.open_dataset(nowcast_file)\n",
    "\n",
    "    varname = \"precip_intensity\" if \"precip_intensity\" in ds_nowcast.data_vars else \"precipitation\"\n",
    "    var = ds_nowcast[varname]\n",
    "    ds_nowcast.close()\n",
    "    if \"ens_number\" in var.dims:\n",
    "        var = var.isel(ens_number=ensemble_number)\n",
    "\n",
    "    data_dict = {}\n",
    "    y_vals = var[\"y\"].values\n",
    "    for pt in points_dinteret:\n",
    "        x_idx = abs(var[\"x\"].values - pt[\"lon\"]).argmin()\n",
    "        y_idx = abs(var[\"y\"].values - pt[\"lat\"]).argmin()\n",
    "        y_idx_flipped = len(y_vals) - 1 - y_idx \n",
    "        rain_series = var[:, y_idx_flipped, x_idx]\n",
    "        data_dict[pt[\"nom\"]] = rain_series.values\n",
    "\n",
    "    first_time = var.time.values[0]\n",
    "    first_time_str = np.datetime_as_string(first_time, unit='m')\n",
    "    safe_time_str = first_time_str.replace(\":\", \"\").replace(\"-\", \"\")\n",
    "\n",
    "    df_points = pd.DataFrame(data_dict, index=rain_series[\"time\"].values)\n",
    "    df_points.index.name = \"time\"\n",
    "    excel_filename = f\"nowcast_points_timeseries_{safe_time_str}.xlsx\"\n",
    "    excel_path = time_folder / excel_filename\n",
    "    df_points.to_excel(excel_path, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Créer un graphique avec des données de observation\n",
    "if make_graph:\n",
    "    ds_obs = xr.open_mfdataset([str(f) for f in observations_input_nowcast])\n",
    "    varname = \"precip_intensity\" if \"precip_intensity\" in ds_obs.data_vars else \"precipitation\"\n",
    "    var = ds_obs[varname]\n",
    "\n",
    "    data_dict = {}\n",
    "    for pt in points_dinteret:\n",
    "        x_idx = abs(var[\"x\"].values - pt[\"lon\"]).argmin()\n",
    "        y_idx = abs(var[\"y\"].values - pt[\"lat\"]).argmin()\n",
    "        rain_series = var[:, y_idx, x_idx]\n",
    "        data_dict[pt[\"nom\"]] = rain_series.values\n",
    "\n",
    "    df_points = pd.DataFrame(data_dict, index=var.time.values)\n",
    "    df_points.index.name = \"time\"\n",
    "\n",
    "    last_time_dt = pd.to_datetime(var.time.values[-1])\n",
    "    safe_time_str = last_time_dt.strftime(\"%Y%m%dT%H%M\")\n",
    "    results_folder = Path(\"results\")\n",
    "    time_folder = results_folder / f\"ens_{ensemble_number}_{safe_time_str}\"\n",
    "    time_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "    x = np.arange(len(df_points.index))\n",
    "    n_locations = len(df_points.columns)\n",
    "    width = 0.8 / n_locations\n",
    "\n",
    "    for i, col in enumerate(df_points.columns):\n",
    "        ax1.bar(\n",
    "            x + i * width,\n",
    "            df_points[col].values,\n",
    "            width=width,\n",
    "            label=col\n",
    "        )\n",
    "\n",
    "    ax1.set_xticks(x + width * (n_locations - 1) / 2)\n",
    "    ax1.set_xticklabels(pd.to_datetime(df_points.index).strftime(\"%Y-%m-%d %H:%M\"), rotation=45, ha=\"right\")\n",
    "    ax1.set_ylabel(\"Intensité des précipitations (mm/h)\")\n",
    "    ax1.set_xlabel(\"Temps\")\n",
    "\n",
    "    df_mm = df_points * 0.25\n",
    "    ax2 = ax1.twinx()\n",
    "    for col in df_mm.columns:\n",
    "        ax2.plot(\n",
    "            x,\n",
    "            df_mm[col].cumsum(),\n",
    "            linestyle=\"--\",\n",
    "            label=f\"Cumul {col} (mm)\"\n",
    "        )\n",
    "    ax2.set_ylabel(\"Somme cumulative (mm)\")\n",
    "    lines_labels = [ax.get_legend_handles_labels() for ax in [ax1, ax2]]\n",
    "    lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "    ax1.legend(lines, labels, loc=\"upper left\")\n",
    "\n",
    "    plt.title(f\"Précipitations et cumul pour toutes les heures\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    graph_filename = f\"observations_graph_{safe_time_str}.png\"\n",
    "    graph_path = time_folder / graph_filename\n",
    "    plt.savefig(graph_path, dpi=150)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Créer un graphique avec des données de nowcast\n",
    "if make_graph:\n",
    "    nowcast_file = nowcasting_folder / \"pysteps_h60b_latest.nc\"\n",
    "    ds_nowcast = xr.open_dataset(nowcast_file)\n",
    "\n",
    "    varname = \"precip_intensity\" if \"precip_intensity\" in ds_nowcast.data_vars else \"precipitation\"\n",
    "    var = ds_nowcast[varname]\n",
    "    ds_nowcast.close()\n",
    "    if \"ens_number\" in var.dims:\n",
    "        var = var.isel(ens_number=ensemble_number)\n",
    "    ds_nowcast.close()\n",
    "\n",
    "    first_time = var.time.values[0]\n",
    "    first_time_str = np.datetime_as_string(first_time, unit='m')\n",
    "    safe_time_str = first_time_str.replace(\":\", \"\").replace(\"-\", \"\")\n",
    "\n",
    "    data_dict = {}\n",
    "    y_vals = var[\"y\"].values\n",
    "    for pt in points_dinteret:\n",
    "        x_idx = abs(var[\"x\"].values - pt[\"lon\"]).argmin()\n",
    "        y_idx = abs(var[\"y\"].values - pt[\"lat\"]).argmin()\n",
    "        y_idx_flipped = len(y_vals) - 1 - y_idx\n",
    "        rain_series = var[:, y_idx_flipped, x_idx]\n",
    "        data_dict[pt[\"nom\"]] = rain_series.values\n",
    "\n",
    "    df_points = pd.DataFrame(data_dict, index=rain_series[\"time\"].values)\n",
    "    df_points.index.name = \"time\"\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "    x = np.arange(len(df_points.index))\n",
    "    width = 0.8 / len(df_points.columns)\n",
    "\n",
    "    for i, col in enumerate(df_points.columns):\n",
    "        ax1.bar(\n",
    "            x + i * width,\n",
    "            df_points[col].values,\n",
    "            width=width,\n",
    "            label=col\n",
    "        )\n",
    "\n",
    "    ax1.set_xticks(x + width * (len(df_points.columns)-1)/2)\n",
    "    ax1.set_xticklabels(df_points.index.strftime(\"%Y-%m-%d %H:%M\"), rotation=45, ha=\"right\")\n",
    "    ax1.set_ylabel(\"Intensité des précipitations (mm/h)\")\n",
    "    ax1.set_xlabel(\"Temps\")\n",
    "    df_points_mm = df_points * 0.25\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    for col in df_points.columns:\n",
    "        ax2.plot(\n",
    "            x,\n",
    "            df_points_mm[col].cumsum(),\n",
    "            linestyle=\"--\",\n",
    "            label=f\"Cumul {col} (mm)\"\n",
    "        )\n",
    "    ax2.set_ylabel(\"Somme cumulative (mm)\")\n",
    "\n",
    "    lines_labels = [ax.get_legend_handles_labels() for ax in [ax1, ax2]]\n",
    "    lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "    ax1.legend(lines, labels, loc=\"upper left\")\n",
    "    plt.title(f\"Intensité de précipitation prévue dans le Nowcast\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    graph_filename = f\"nowcast_graph_{safe_time_str}.png\"\n",
    "    graph_path = time_folder / graph_filename\n",
    "    plt.savefig(graph_path, dpi=150)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "if make_gif:\n",
    "    safe_time_str = target_datetime.strftime(\"%Y%m%dT%H%M\")\n",
    "    time_folder = results_folder / f\"ens_{ensemble_number}_{safe_time_str}\"\n",
    "    gif_files = list(time_folder.glob(\"*.gif\"))\n",
    "\n",
    "    obs_gif = next((f for f in gif_files if \"observations\" in f.name.lower()), None)\n",
    "    nowcast_gif = next((f for f in gif_files if \"nowcast\" in f.name.lower()), None)\n",
    "\n",
    "    def add_title(frame, title):\n",
    "        \"\"\"Voeg een grote zwarte titel toe bovenaan het frame.\"\"\"\n",
    "        frame = frame.convert(\"RGBA\")\n",
    "        draw = ImageDraw.Draw(frame)\n",
    "        try:\n",
    "            font = ImageFont.truetype(\"arial.ttf\", 500)\n",
    "        except:\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "        text_bbox = draw.textbbox((0, 0), title, font=font)\n",
    "        text_width = text_bbox[2] - text_bbox[0]\n",
    "        x = (frame.width - text_width) // 2\n",
    "        y = 20\n",
    "\n",
    "        draw.text((x, y), title, fill=\"black\", font=font)\n",
    "        return frame\n",
    "\n",
    "    if obs_gif and nowcast_gif:\n",
    "        gif1 = Image.open(obs_gif)\n",
    "        gif2 = Image.open(nowcast_gif)\n",
    "\n",
    "        frames = []\n",
    "        for frame in ImageSequence.Iterator(gif1):\n",
    "            frames.append(add_title(frame.copy(), \"OBSERVATIONS\"))\n",
    "        for frame in ImageSequence.Iterator(gif2):\n",
    "            frames.append(add_title(frame.copy(), \"NOWCAST\"))\n",
    "\n",
    "        combination_path = time_folder / \"combination.gif\"\n",
    "        frames[0].save(\n",
    "            combination_path,\n",
    "            save_all=True,\n",
    "            append_images=frames[1:],\n",
    "            duration=600,\n",
    "            loop=0\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
