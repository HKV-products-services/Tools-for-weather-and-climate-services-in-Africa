{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutoriel : Télécharger, prétraiter et analyser les observations satellitaires de précipitations HSAF H60B\n",
    "Ce tutoriel vous guide pas à pas pour :\n",
    "\n",
    "1. Télécharger les fichiers H60B depuis le serveur HSAF.\n",
    "\n",
    "2. Prétraiter les données pour qu’elles soient utilisables dans vos analyses (ex. régrillage en latitude/longitude, extraction d’une zone d’intérêt).\n",
    "\n",
    "3. Analyser les précipitations pour des points spécifiques ou pour toute une région, incluant la visualisation et le calcul de cumul.\n",
    "\n",
    "L’objectif est de vous familiariser avec les fichiers HSAF H60B. \n",
    "\n",
    "Qu’est-ce que HSAF H60B?\n",
    "- H60B donne des estimations de pluie à partir des données du satellite MSG SEVIRI.\n",
    "- Les informations sont mises à jour toutes les 15 minutes pour l’Afrique et l’Europe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étape 1 : Importer les bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliothèques de base\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import math\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "\n",
    "# Bibliothèques pour la reprojection (changement de système de coordonnées géographiques)\n",
    "import rioxarray \n",
    "from pyproj import CRS\n",
    "from pyresample.geometry import AreaDefinition\n",
    "try:\n",
    "    from satpy.readers.core._geos_area import get_area_extent\n",
    "except ImportError:\n",
    "    from satpy.readers._geos_area import get_area_extent\n",
    "\n",
    "# Bibliothèques pour la gestion des données et des fichiers\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta, date\n",
    "from ftplib import FTP   # Pour télécharger les fichiers depuis un serveur FTP\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "# Supprimer/ignorer les avertissements pour avoir une sortie plus propre\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Toutes les bibliothèques ont été importées avec succès!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étape 2 : Configurer les dossiers de données\n",
    "Organiser la structure des dossiers de données avec des chemins relatifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer des dossiers pour nos données\n",
    "data_folder = Path(\"./h60b_data\")\n",
    "raw_folder = data_folder / \"raw\"\n",
    "processed_folder = data_folder / \"processed\"\n",
    "\n",
    "# Créer les répertoires s'ils n'existent pas encore\n",
    "raw_folder.mkdir(parents=True, exist_ok=True)\n",
    "processed_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Dossiers de données créés :\")\n",
    "print(f\"Données brutes : {raw_folder}\")\n",
    "print(f\"Données traitées : {processed_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étape 3 : Configuration de la connexion FTP\n",
    "- Vous devez vous inscrire sur https://hsaf.meteoam.it/User/Register pour obtenir des identifiants\n",
    "- Définir le nom du serveur FTP, le dossier sur le serveur FTP, ainsi que le nom d'utilisateur et le mot de passe\n",
    "- FTP (File Transfer Protocol) est un protocole qui permet de transférer des fichiers entre un ordinateur local et un serveur distant sur Internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Détails du serveur FTP HSAF\n",
    "ftp_server = \"ftphsaf.meteoam.it\"\n",
    "ftp_directory = \"./h60B/h60_cur_mon_data/\"\n",
    "\n",
    "# Pour ce tutoriel, nous utilisons des identifiants d'exemple\n",
    "username = \"xxxxxx\"  \t\t\t# Remplacez par votre nom d'utilisateur réel\n",
    "password = \"xxxxxx!\"        # Remplacez par votre mot de passe réel\n",
    "\n",
    "print(f\"Serveur FTP : {ftp_server}\")\n",
    "print(f\"Dossier sur le serveur FTP : {ftp_directory}\")\n",
    "print(\"Note : N'oubliez pas de remplacer le nom d'utilisateur/mot de passe par vos identifiants HSAF réels !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étape 4 : Se connecter au serveur FTP et lister les fichiers disponibles\n",
    "Cette étape est utile pour savoir quels fichiers vous pouvez télécharger avant de les traiter.\n",
    "Ici, nous utilisons la bibliothèque ftplib pour :\n",
    "1. Se connecter au serveur FTP HSAF avec vos identifiants\n",
    "2. Accéder au dossier contenant les fichiers H60B\n",
    "3. Lister tous les fichiers disponibles dans ce dossier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_h60b_timestamp(filename):\n",
    "    \"\"\"\n",
    "    Extraire le timestamp à partir du nom de fichier H60B.\n",
    "    \n",
    "    Les fichiers H60B disponibles sur le serveur HSAF contiennent dans leur nom une indication de date et d'heure sous la forme :h60B_YYYYMMDD_HHMM_xxx.nc\n",
    "\n",
    "    Cette fonction permet d'extraire ces informations et de les convertir en objet datetime Python, afin de pouvoir trier les fichiers,\n",
    "    sélectionner des intervalles de temps, ou effectuer toute autre manipulation temporelle dans le script.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Diviser le nom du fichier par \"_\"\n",
    "        parts = filename.split(\"_\")\n",
    "        date_str = parts[1]                  # YYYYMMDD\n",
    "        time_str = parts[2].split(\".\")[0]    # HHMM\n",
    "        # Combiner la date et l'heure et convertir en objet datetime\n",
    "        timestamp = datetime.strptime(f\"{date_str}{time_str}\", \"%Y%m%d%H%M\")\n",
    "        return timestamp\n",
    "    except:\n",
    "        # Si le nom de fichier n'est pas valide, retourner None\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_h60b_files_full():\n",
    "    \"\"\"\n",
    "    Lister tous les fichiers H60B disponibles sur le serveur FTP HSAF\n",
    "    et afficher le premier et le dernier fichier disponibles.\n",
    "\n",
    "    Les fichiers H60B sur le serveur HSAF ne sont conservés que pour les derniers mois.\n",
    "    Cette fonction permet de :\n",
    "      1. Se connecter au serveur FTP HSAF avec vos identifiants.\n",
    "      2. Lister tous les fichiers H60B présents dans le répertoire.\n",
    "      3. Extraire la date et l'heure de chaque fichier à partir de son nom.\n",
    "      4. Identifier le premier et le dernier fichier disponible.\n",
    "\n",
    "    Cette opération est importante pour connaître la période de disponibilité\n",
    "    des données H60B avant de lancer une analyse ou de sélectionner des fichiers\n",
    "    pour une plage temporelle spécifique. \n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"Connexion au serveur FTP HSAF...\")\n",
    "        with FTP(ftp_server) as ftp:\n",
    "            # Se connecter avec les identifiants\n",
    "            ftp.login(username, password)\n",
    "            print(\"Connexion réussie !\")\n",
    "            \n",
    "            # Aller dans le répertoire où se trouvent les fichiers H60B\n",
    "            ftp.cwd(ftp_directory)\n",
    "            print(f\"Répertoire actuel sur le serveur : {ftp_directory}\")\n",
    "            \n",
    "            # Récupérer la liste de tous les fichiers du répertoire\n",
    "            files = []\n",
    "            ftp.dir(lambda line: files.append(line.split()[-1]))\n",
    "            \n",
    "            # Ne garder que les fichiers H60B (commençant par 'h60')\n",
    "            h60b_files = [f for f in files if f.startswith(\"h60\")]\n",
    "            print(f\"{len(h60b_files)} fichiers H60B trouvés sur le serveur\")\n",
    "            \n",
    "            # Extraire les timestamps et filtrer les fichiers invalides\n",
    "            timestamps_files = [(parse_h60b_timestamp(f), f) \n",
    "                                for f in h60b_files \n",
    "                                if parse_h60b_timestamp(f) is not None]\n",
    "            \n",
    "            if not timestamps_files:\n",
    "                print(\"Aucun fichier avec timestamp valide trouvé.\")\n",
    "                return []\n",
    "            \n",
    "            # Trier les fichiers par timestamp croissant\n",
    "            timestamps_files.sort()\n",
    "            \n",
    "            # Récupérer le premier et le dernier fichier\n",
    "            first_file = timestamps_files[0]\n",
    "            last_file  = timestamps_files[-1]\n",
    "            \n",
    "            print(f\"\\nPremier fichier disponible : {first_file[1]} ({first_file[0]})\")\n",
    "            print(f\"Dernier fichier disponible : {last_file[1]} ({last_file[0]})\")\n",
    "            \n",
    "            # Retourner la liste complète des fichiers triés\n",
    "            return [f[1] for f in timestamps_files]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la connexion FTP : {e}\")\n",
    "        print(\"Assurez-vous de vous être inscrit sur https://hsaf.meteoam.it/ et d'avoir des identifiants valides\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer la fonction ci-dessus pour récupérer les fichiers disponibles\n",
    "# Tout d'abord, se connecter au serveur FTP et récupérer la liste complète des fichiers\n",
    "# Nous vérifions combien de fichiers de données sont disponibles et quelle est la période couverte\n",
    "all_files = list_h60b_files_full()\n",
    "\n",
    "# Extraire les timestamps pour chaque fichier\n",
    "timestamps_files = [(parse_h60b_timestamp(f), f) for f in all_files if parse_h60b_timestamp(f)]\n",
    "timestamps_files.sort()  # Tri croissant selon les dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_files_by_steps(start_time, n_steps=1, timestamps_files=timestamps_files):\n",
    "    \"\"\"\n",
    "    Sélectionne un nombre défini de fichiers consécutifs à partir d'un moment de départ donné.\n",
    "    \n",
    "    Parameters:\n",
    "    - start_time : datetime, le moment à partir duquel commencer la sélection\n",
    "    - n_steps : int, nombre de fichiers consécutifs à sélectionner\n",
    "    - timestamps_files : liste de tuples (timestamp, nom_fichier), déjà triée par date\n",
    "    \n",
    "    La fonction parcourt la liste des fichiers disponibles et choisit le premier fichier\n",
    "    dont le timestamp est supérieur ou égal au moment de départ, puis continue pour les étapes suivantes.\n",
    "    \"\"\"\n",
    "    selected_files = []\n",
    "    last_ts = start_time  # moment de départ pour la recherche\n",
    "    \n",
    "    for _ in range(n_steps):\n",
    "        next_file = None\n",
    "        # Chercher le fichier disponible le plus proche après last_ts\n",
    "        for ts, f in timestamps_files:\n",
    "            if ts >= last_ts:\n",
    "                next_file = (ts, f)\n",
    "                break\n",
    "        \n",
    "        if next_file:\n",
    "            selected_files.append(next_file[1])                    # Ajouter le fichier à la sélection\n",
    "            last_ts = next_file[0] + timedelta(minutes=15)         # Déplacer le seuil juste après ce fichier\n",
    "        else:\n",
    "            print(f\"Aucun fichier disponible après {last_ts}\")\n",
    "            break\n",
    "    \n",
    "    return selected_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étape 5 : Sélection d'une période pour l'importation des données HSAF\n",
    "1. Nous choisissons un moment de départ (start_datetime) à partir duquel nous voulons commencer à récupérer les données.\n",
    "2. Nous définissons le nombre de fichiers consécutifs à récupérer (n_steps). Chaque fichier correspond à un pas de temps de 15 minutes.\n",
    "3. La fonction select_files_by_steps sélectionne automatiquement les fichiers disponibles qui correspondent à cette période.\n",
    "\n",
    "Note: La date de départ doit se situer entre le premier et le dernier fichier disponible sur le serveur, que nous avons identifié avec list_h60b_files_full()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_datetime = datetime(2025, 8, 10, 8, 0)  \t# Définir le moment de départ pour récupérer les fichiers HSAF, Format : datetime(Année, Mois, Jour, Heure, Minute)                                      \n",
    "n_steps = 10  \t\t\t\t\t\t\t\t\t# Nombre de fichiers à sélectionner, chaque pas de temps correspond à 15 minutes\n",
    "\n",
    "# Sélection des fichiers\n",
    "selected_files = select_files_by_steps(start_datetime, n_steps)\n",
    "\n",
    "# Affichage des fichiers sélectionnés avec leurs timestamps\n",
    "print(\"\\nFichiers sélectionnés :\")\n",
    "for f in selected_files:\n",
    "    ts = parse_h60b_timestamp(f)\n",
    "    print(f\" - {ts} : {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation et prétraitement des données HSAF\n",
    "\n",
    "Nous allons maintenant importer les données de précipitation HSAF depuis le serveur. Avant de pouvoir les utiliser et les analyser correctement, il est nécessaire de réaliser un prétraitement.\n",
    "Une étape importante de ce prétraitement est, par exemple, la conversion d'une grille satellite (satellite grid) en une grille latitude-longitude (lat-lon grid), afin de pouvoir manipuler et visualiser les données plus facilement.\n",
    "#\n",
    "Dans ce tutoriel, nous allons d'abord travailler sur une seule étape temporelle, c'est-à-dire un seul fichier de données. Cela nous permet de comprendre clairement chaque étape du prétraitement. Une fois cette étape comprise, nous pourrons appliquer le même processus de manière répétée dans une boucle pour traiter un grand nombre de fichiers consécutifs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étape 6 : Télécharger un seul fichier\n",
    "Cette étape montre comment télécharger un fichier H60B spécifique depuis le serveur FTP\n",
    "1. Vérifier si le fichier existe déjà dans le dossier local pour éviter de le retélécharger\n",
    "2. Télécharger le fichier compressé (.gz) depuis le serveur FTP\n",
    "3. Décompresser le fichier en format NetCDF (.nc)\n",
    "4. Supprimer le fichier compressé pour économiser de l’espace disque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_h60b_file(filename, output_folder=None):\n",
    "    \"\"\"Télécharger et décompresser un fichier H60B unique\"\"\"\n",
    "\n",
    "    target_folder = Path(output_folder) if output_folder else raw_folder\n",
    "    target_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    gz_path = target_folder / filename\n",
    "    nc_path = target_folder / filename.replace(\".gz\", \"\")\n",
    "\n",
    "    # Vérifier si le fichier existe déjà localement\n",
    "    if nc_path.exists():\n",
    "        print(f\"Le fichier existe déjà : {nc_path.name}\")\n",
    "        return str(nc_path)\n",
    "\n",
    "    try:\n",
    "        print(f\"Téléchargement de {filename}...\")\n",
    "\n",
    "        # Télécharger le fichier compressé depuis le serveur FTP\n",
    "        with FTP(ftp_server) as ftp:\n",
    "            ftp.login(username, password)\n",
    "            ftp.cwd(ftp_directory)\n",
    "\n",
    "            with open(gz_path, \"wb\") as f:\n",
    "                ftp.retrbinary(f\"RETR {filename}\", f.write)\n",
    "\n",
    "        file_size = gz_path.stat().st_size / (1024*1024)  # Taille en MB\n",
    "        print(f\"Téléchargé {filename} ({file_size:.1f} MB)\")\n",
    "\n",
    "        # Décompresser le fichier\n",
    "        print(f\"Décompression du fichier...\")\n",
    "        with gzip.open(gz_path, \"rb\") as f_in:\n",
    "            with open(nc_path, \"wb\") as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "        # Supprimer le fichier compressé pour économiser de l'espace\n",
    "        gz_path.unlink()\n",
    "\n",
    "        final_size = nc_path.stat().st_size / (1024*1024)  # Taille finale en MB\n",
    "        print(f\"Décompressé en {nc_path.name} ({final_size:.1f} MB)\")\n",
    "\n",
    "        return str(nc_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du téléchargement de {filename} : {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Télécharger un seul fichier \n",
    "if selected_files:\n",
    "    latest_file = selected_files[-1]  # Prendre le fichier le plus récent de la liste\n",
    "    downloaded_file = download_h60b_file(latest_file)\n",
    "else:\n",
    "    # Pour la démonstration, on simule un fichier si aucun n'est disponible\n",
    "    print(\"Aucun fichier disponible depuis le FTP, utilisation de données exemple pour la démonstration\")\n",
    "    downloaded_file = None\n",
    "         \n",
    "print(downloaded_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le dossier h60b_data\\raw\\, vous pouvez maintenant vérifier si un fichier HSAF a été téléchargé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étape 7: Examiner les données brutes H60B\n",
    "1. Vérifier la structure du fichier H60B\n",
    "2. Voir quelles variables et dimensions sont disponibles\n",
    "3. Observer la variable de précipitation 'rr' et ses valeurs réelles\n",
    "4. Connaître les informations de projection si présentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regardons à quoi ressemble un fichier H60B brut\n",
    "def examine_raw_data(filepath):\n",
    "    \"\"\"Examiner la structure d’un fichier H60B brut\"\"\"\n",
    "    \n",
    "    if not filepath or not Path(filepath).exists():\n",
    "        print(\"Aucun fichier disponible pour l'examen\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Examen du fichier H60B brut : {Path(filepath).name}\")\n",
    "    \n",
    "    # Ouvrir le dataset NetCDF avec xarray\n",
    "    ds = xr.open_dataset(filepath, decode_cf=False)\n",
    "    \n",
    "    print(f\"\\nStructure du dataset :\")\n",
    "    print(f\"   Dimensions : {dict(ds.dims)}\")        # ex : temps, x, y\n",
    "    print(f\"   Variables : {list(ds.data_vars)}\")    # ex : rr (précipitations)\n",
    "    print(f\"   Coordonnées : {list(ds.coords)}\")     # ex : latitude, longitude\n",
    "    \n",
    "    # Observer la variable de précipitations\n",
    "    rr = ds['rr']\n",
    "    print(f\"\\nVariable de précipitation 'rr' :\")\n",
    "    print(f\"   Forme : {rr.shape}\")\n",
    "    print(f\"   Type de données : {rr.dtype}\")\n",
    "    print(f\"   Valeurs brutes : de {rr.min().values} à {rr.max().values}\")\n",
    "    \n",
    "    # Vérifier l’encodage (facteur d’échelle, offset)\n",
    "    scale_factor = rr.encoding.get('scale_factor', 1.0)\n",
    "    add_offset = rr.encoding.get('add_offset', 0.0)\n",
    "    print(f\"   Facteur d’échelle : {scale_factor}\")\n",
    "    print(f\"   Décalage ajouté : {add_offset}\")\n",
    "    \n",
    "    # Calculer la plage réelle des précipitations après application du facteur d’échelle\n",
    "    rr_scaled = rr.astype('float32') * scale_factor + add_offset  # rr signifie rainfall rate\n",
    "    print(f\"   Plage réelle des précipitations : de {rr_scaled.min().values:.3f} à {rr_scaled.max().values:.3f} mm/h\")\n",
    "    \n",
    "    # Afficher les informations de projection si disponibles\n",
    "    if 'gdal_projection' in ds.attrs:\n",
    "        print(f\"\\nProjection : {ds.attrs['gdal_projection']}\")\n",
    "    \n",
    "    return ds\n",
    "\n",
    "raw_dataset = examine_raw_data(downloaded_file)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étape 8 : Visualiser les données brutes\n",
    "Pour valider les données brutes, nous allons procéder de la manière suivante :\n",
    "\n",
    "1. Tracer une carte des précipitations pour observer leur répartition spatiale.\n",
    "2. Créer un histogramme afin de visualiser la distribution des valeurs de pluie.\n",
    "3. Calculer quelques statistiques de base pour comprendre l’intensité et l’étendue des précipitations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raw_data(ds, filename=None):\n",
    "    \"\"\"Créer une visualisation simple des données H60B brutes\"\"\"\n",
    "    \n",
    "    if ds is None:\n",
    "        print(\"Aucun dataset à afficher\")\n",
    "        return\n",
    "    \n",
    "    # Extraire la date/heure depuis le nom du fichier si fourni\n",
    "    if filename is not None:\n",
    "        match = re.search(r'(\\d{8})_(\\d{4})', filename)\n",
    "        if match:\n",
    "            date_str, time_str = match.groups()\n",
    "            timestamp = f\"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]} {time_str[:2]}:{time_str[2:]}\"\n",
    "        else:\n",
    "            timestamp = \"Inconnu\"\n",
    "    else:\n",
    "        timestamp = \"Inconnu\"\n",
    "\n",
    "    print(f\"Affichage des données pour le fichier : {filename} (temps : {timestamp})\")\n",
    "\n",
    "    # Appliquer le facteur d'échelle: Cela est utilisé pour réduire l’espace de stockage, mais n’a aucune incidence sur les résultats.\n",
    "    rr = ds['rr']\n",
    "    scale_factor = rr.encoding.get('scale_factor', 0.1)\n",
    "    add_offset = rr.encoding.get('add_offset', 0.0)\n",
    "    precip = rr.astype('float32') * scale_factor + add_offset\n",
    "    \n",
    "    # Créez une figure.\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Carte des précipitations\n",
    "    im1 = ax1.imshow(precip.values, cmap='Blues', vmin=0, vmax=10)\n",
    "    ax1.set_title(f'Taux de précipitation H60B (mm/h)\\nTemps : {timestamp}')\n",
    "    ax1.set_xlabel('Pixels X')\n",
    "    ax1.set_ylabel('Pixels Y')\n",
    "    plt.colorbar(im1, ax=ax1, label='mm/h')\n",
    "    \n",
    "    # Histogramme\n",
    "    valid_precip = precip.values[precip.values >= 0]\n",
    "    ax2.hist(valid_precip[valid_precip > 0], bins=50, alpha=0.7, edgecolor='black')\n",
    "    ax2.set_xlabel('Taux de précipitation (mm/h)')\n",
    "    ax2.set_ylabel('Fréquence')\n",
    "    ax2.set_title('Distribution des valeurs de précipitation')\n",
    "    ax2.set_yscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistiques\n",
    "    print(f\"\\nStatistiques de précipitation :\")\n",
    "    print(f\"   Total de pixels : {precip.size:,}\")\n",
    "    print(f\"   Pixels avec pluie (>0 mm/h) : {np.sum(valid_precip > 0):,}\")\n",
    "    print(f\"   Couverture de pluie : {100 * np.sum(valid_precip > 0) / len(valid_precip):.1f}%\")\n",
    "    print(f\"   Taux de pluie maximum : {np.max(valid_precip):.1f} mm/h\")\n",
    "    print(f\"   Taux de pluie moyen (zones pluvieuses) : {np.mean(valid_precip[valid_precip > 0]):.2f} mm/h\")\n",
    "\n",
    "plot_raw_data(raw_dataset, filename=Path(downloaded_file).name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarquez que la grille du satellite est en pixels X et Y, pas en latitude/longitude.\n",
    "Chaque cellule du fichier H60B correspond à un pixel du capteur du satellite.\n",
    "Si vous voulez utiliser ces données sur une carte géographique ou avec QGIS, il faudra les reprojeter pour obtenir des coordonnées latitude/longitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étape 9 : Prétraiter les données pour une grille latitude/longitude\n",
    "\n",
    "Étapes principales :\n",
    "1. Charger le fichier H60B brut\n",
    "2. Appliquer les facteurs d’échelle et renommer la variable précipitation\n",
    "3. Définir correctement le CRS (système de projection)\n",
    "4. Créer des coordonnées spatiales cohérentes\n",
    "5. Reprojeter les données vers WGS84 (latitude/longitude)\n",
    "6. Définir les métadonnées globales et variables\n",
    "7. Sauvegarder le fichier NetCDF prêt à l’usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_single_file(raw_file: str, output_folder=None):\n",
    "    \"\"\"Prétraiter un fichier H60B unique pour WGS84 avec noms de variables cohérents.\"\"\"\n",
    "    \n",
    "    # Bepaal doelmap: standaard processed_folder tenzij anders opgegeven\n",
    "    target_folder = Path(output_folder) if output_folder else processed_folder\n",
    "    target_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    filename = Path(raw_file).name\n",
    "\n",
    "    # Extraire le timestamp depuis le nom du fichier et définir le chemin de sortie\n",
    "    timestamp = parse_h60b_timestamp(filename)\n",
    "    hsaf_filename = f\"HSAF-H60B_{timestamp.strftime('%Y%m%dT%H%M%S')}.nc\"\n",
    "    output_path = target_folder / hsaf_filename\n",
    "\n",
    "    # Vérifier si le fichier prétraité existe déjà\n",
    "    if output_path.exists():\n",
    "        print(f\"Fichier déjà prétraité : {hsaf_filename} -> Ignorer le prétraitement\")\n",
    "        return str(output_path)\n",
    "\n",
    "    print(f\"Prétraitement du fichier H60B : {filename} -> {hsaf_filename}\")\n",
    "    # --- Définitions des systèmes de coordonnées\n",
    "    crs_in = \"+proj=geos +a=6378.169 +b=6356.584 +h=35785.831 +lat_0=0 +lon_0=0.000000\"  # CRS d’origine (satellite)\n",
    "    crs_out = \"EPSG:4326\"  # CRS de sortie : latitude/longitude\n",
    "\n",
    "    # Charger le fichier brut sans décodage automatique CF\n",
    "    ds = xr.open_dataset(raw_file, decode_coords=\"all\", decode_cf=False)\n",
    "\n",
    "    # Renommer les coordonnées et appliquer le facteur d’échelle\n",
    "    ds = ds.rename({\"nx\": \"x\", \"ny\": \"y\"})\n",
    "    rr_raw = ds[\"rr\"]\n",
    "    scale_factor = rr_raw.encoding.get(\"scale_factor\", 0.1)\n",
    "    add_offset  = rr_raw.encoding.get(\"add_offset\", 0.0)\n",
    "    ds[\"rr\"] = rr_raw.astype(\"float32\") * scale_factor + add_offset\n",
    "    ds[\"rr\"].encoding.clear()\n",
    "    ds[\"rr\"].attrs.clear()\n",
    "    ds = ds[[\"rr\"]].astype(\"float32\")\n",
    "\n",
    "    # Utiliser le CRS directement depuis le fichier pour garder exact h, a, b, lon_0, etc.\n",
    "    source_crs = CRS.from_proj4(ds.attrs[\"gdal_projection\"])\n",
    "    crs_in = source_crs.to_proj4()  # CRS exact du fichier\n",
    "    crs_out = \"EPSG:4326\"\n",
    "\n",
    "    # --- Définir l'étendue CGMS et les coordonnées\n",
    "    cgms_projection = (\n",
    "        \"+proj=geos +coff=1856.000000 +cfac=13642337.000000 \"\n",
    "        \"+loff=1856.000000 +lfac=13642337.000000 \"\n",
    "        \"+spp=0.000000 +r_eq=6378.169000 +r_pol=6356.583800 +h=42164.000000\"\n",
    "    )\n",
    "    matches = re.findall(r\"\\+?(\\w+)\\s*=\\s*([^\\s]+)\", cgms_projection)\n",
    "    parse_dict = {k: v for k, v in matches}\n",
    "\n",
    "    # Calcul de l'étendue de la zone du satellite (area_extent)\n",
    "    cd = source_crs.to_dict()\n",
    "    area_extent = get_area_extent({\n",
    "        \"scandir\": \"N2S\",                                                           # scandir : direction de balayage du satellite (N2S = Nord vers Sud)\n",
    "        \"h\": float(parse_dict[\"h\"]) * 1000 - float(parse_dict[\"r_eq\"]) * 1000,      # h : hauteur du satellite au-dessus de la Terre       \n",
    "        \"loff\": float(parse_dict[\"loff\"]),                                          # loff, coff : décalages de ligne et de colonne (début du raster)\n",
    "        \"coff\": float(parse_dict[\"coff\"]),                                          \n",
    "        \"lfac\": float(parse_dict[\"lfac\"]),                                          # lfac, cfac : facteurs d'échelle pour les lignes et colonnes\n",
    "        \"cfac\": float(parse_dict[\"cfac\"]),\n",
    "        \"ncols\": ds.x.size,                                                         # ncols, nlines : nombre de colonnes et lignes du raster\n",
    "        \"nlines\": ds.y.size,\n",
    "    })\n",
    "    # Résultat : (min_x, max_x, min_y, max_y) dans la projection originale, utilisé pour reprojeter correctement le raster.\n",
    "\n",
    "    area_def_src = AreaDefinition(\n",
    "        \"areaD\",\n",
    "        cd[\"proj\"],\n",
    "        \"areaD\",\n",
    "        {\"lon_0\": cd[\"lon_0\"], \"a\": cd[\"a\"], \"b\": cd[\"b\"], \"h\": cd[\"h\"], \"proj\": cd[\"proj\"]},\n",
    "        ds.y.size,\n",
    "        ds.x.size,\n",
    "        (area_extent[0], area_extent[1], area_extent[2], area_extent[3]),\n",
    "    )\n",
    "\n",
    "    # Créer de nouvelles coordonnées X et Y\n",
    "    x, y = area_def_src.get_proj_coords()\n",
    "    new_x_coords = np.linspace(x.min(), x.max(), num=ds.sizes[\"x\"])\n",
    "    new_y_coords = np.linspace(y.max(), y.min(), num=ds.sizes[\"y\"])\n",
    "    ds = ds.assign_coords(y=(\"y\", new_y_coords), x=(\"x\", new_x_coords))\n",
    "\n",
    "    # Écrire le CRS qui correspond aux unités des coordonnées\n",
    "    ds = ds.rio.write_crs(crs_in)\n",
    "\n",
    "    # Renommer la variable, ajouter le temps et trier les dimensions\n",
    "    ds = ds.rename({\"rr\": \"precip_intensity\"}).sortby(\"y\")\n",
    "    ds = ds.expand_dims(\"time\").assign_coords(time=(\"time\", [timestamp]))\n",
    "    ds = ds.transpose(\"time\", \"y\", \"x\")\n",
    "\n",
    "    # Définir les attributs de la variable de précipitation\n",
    "    ds.precip_intensity.attrs = {\n",
    "        \"standard_name\": \"precipitation_flux\",\n",
    "        \"long_name\": \"Flux de précipitation dérivé des propriétés optiques des nuages\",\n",
    "        \"units\": \"kg m-2 h-1\",\n",
    "    }\n",
    "\n",
    "    # Remplacer les valeurs invalides par NaN\n",
    "    ds[\"precip_intensity\"] = ds[\"precip_intensity\"].where(ds[\"precip_intensity\"] >= 0, np.nan)\n",
    "    da = ds[\"precip_intensity\"].rio.write_nodata(np.nan, encoded=True)\n",
    "    ds[\"precip_intensity\"] = da\n",
    "\n",
    "    # Vérification rapide avant reprojection\n",
    "    print(\"Avant reprojection : min/max\", float(ds.precip_intensity.min()), float(ds.precip_intensity.max()))\n",
    "\n",
    "    # Reprojection vers WGS84\n",
    "    print(\"Reprojection des données H60B vers WGS84\")\n",
    "    ds = ds.rio.reproject(crs_out, nodata=np.nan)\n",
    "\n",
    "    # Vérification après reprojection\n",
    "    print(\"Après reprojection : min/max\", float(ds.precip_intensity.min(skipna=True)), float(ds.precip_intensity.max(skipna=True)))\n",
    "\n",
    "    # Nettoyer l'encodage après reprojection\n",
    "    for var_name in ds.data_vars:\n",
    "        ds[var_name].encoding.clear()\n",
    "        for attr in [\"_FillValue\", \"missing_value\", \"fill_value\", \"FillValue\"]:\n",
    "            ds[var_name].attrs.pop(attr, None)\n",
    "\n",
    "    # Ordre final des dimensions\n",
    "    ds = ds.transpose(\"time\", \"y\", \"x\")\n",
    "\n",
    "    # Définir les attributs CF pour les coordonnées\n",
    "    ds.x.attrs = {\"standard_name\": \"longitude\", \"long_name\": \"longitude\", \"units\": \"degrees_east\", \"axis\": \"X\"}\n",
    "    ds.y.attrs = {\"standard_name\": \"latitude\", \"long_name\": \"latitude\", \"units\": \"degrees_north\", \"axis\": \"Y\"}\n",
    "    ds.time.attrs = {\"standard_name\": \"time\", \"long_name\": \"time\", \"axis\": \"T\"}\n",
    "\n",
    "    # Définir les attributs globaux du dataset\n",
    "    ds.attrs = {\n",
    "        \"Conventions\": \"CF-1.6\",\n",
    "        \"title\": \"RAINSAT H60B MSG SEVIRI Precipitation\",\n",
    "        \"source\": \"EUMETSAT H-SAF H60B\",\n",
    "        \"creator\": \"HKV services\",\n",
    "        \"creation_date\": date.today().strftime(\"%Y-%m-%d\"),\n",
    "        \"time_coverage_start\": timestamp.strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
    "        \"time_coverage_end\": (timestamp + timedelta(minutes=15)).strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
    "        \"geospatial_lat_min\": float(ds.y.min()),\n",
    "        \"geospatial_lat_max\": float(ds.y.max()),\n",
    "        \"geospatial_lon_min\": float(ds.x.min()),\n",
    "        \"geospatial_lon_max\": float(ds.x.max()),\n",
    "        \"crs\": crs_out,\n",
    "        \"product_details\": \"https://hsaf.meteoam.it/Products/Detail?prod=H60B\",\n",
    "        \"data_source\": \"hsaf-h60b\",\n",
    "    }\n",
    "\n",
    "    # Encodage pour NetCDF\n",
    "    encoding = {\n",
    "        \"precip_intensity\": {\"dtype\": \"float32\", \"zlib\": True, \"complevel\": 4, \"_FillValue\": -999.0},\n",
    "        \"time\": {\"units\": \"minutes since 1970-01-01 00:00:00\", \"dtype\": \"float64\"},\n",
    "    }\n",
    "\n",
    "    # Sauvegarder le fichier NetCDF prétraité\n",
    "    ds.to_netcdf(output_path, encoding=encoding)\n",
    "    ds.close()\n",
    "    print(f\"Fichier H60B prétraité avec succès : {hsaf_filename}\")\n",
    "    return str(output_path)\n",
    "\n",
    "# Exécuter le prétraitement pour le fichier téléchargé\n",
    "processed_file = preprocess_single_file(downloaded_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étape 10 : Visualiser les données prétraitées en latitude et longitude\n",
    "Ici, nous allons créer deux graphiques côte à côte pour mieux comprendre les données prétraitées :\n",
    "1. Nous réalisons une carte complète des précipitations (mm/h).\n",
    "2. Nous mettons en évidence uniquement les zones pluvieuses (> 0,1 mm/h) afin de mieux visualiser où il pleut réellement.\n",
    "\n",
    "En parallèle, nous affichons quelques statistiques résumées pour évaluer la qualité et l’étendue des données:\n",
    "- La taille de la grille utilisée\n",
    "- Le nombre de pixels valides\n",
    "- Le nombre et la couverture des pixels pluvieux\n",
    "- L’intensité maximale et moyenne de la pluie dans les zones pluvieuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_processed_data(processed_file):\n",
    "    \"\"\"Visualiser les données de précipitation prétraitées\"\"\"\n",
    "    \n",
    "    # Charger le fichier NetCDF prétraité\n",
    "    ds = xr.open_dataset(processed_file)\n",
    "    print(ds)\n",
    "    \n",
    "    # Sélectionner le premier pas de temps (souvent unique pour H60B)\n",
    "    precip = ds[\"precip_intensity\"].isel(time=0)\n",
    "    \n",
    "    # Créer la figure avec deux sous-graphes côte à côte\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    # --- Graphe 1 : Carte complète des précipitations\n",
    "    im1 = precip.plot(ax=ax1, cmap='Blues', vmin=0, vmax=10, \n",
    "                      cbar_kwargs={'label': 'Précipitation (mm/h)'})\n",
    "    ax1.set_title('Données H60B prétraitées')\n",
    "    ax1.set_aspect('equal')  # Assurer que les axes X et Y ont la même échelle\n",
    "    \n",
    "    # --- Graphe 2 : Zoom sur les zones pluvieuses uniquement\n",
    "    rain_mask = precip.values > 0.1  # Zones avec > 0.1 mm/h\n",
    "    if np.any(rain_mask):\n",
    "        im2 = ax2.imshow(np.where(rain_mask, precip.values, np.nan), \n",
    "                        cmap='viridis', vmin=0.1)\n",
    "        ax2.set_title('Zones pluvieuses uniquement (> 0,1 mm/h)')\n",
    "        plt.colorbar(im2, ax=ax2, label='mm/h')\n",
    "    else:\n",
    "        # Affichage d’un message si aucune pluie significative\n",
    "        ax2.text(0.5, 0.5, 'Aucune pluie\\nsignificative détectée', \n",
    "                 ha='center', va='center', transform=ax2.transAxes)\n",
    "        ax2.set_title('Zones pluvieuses uniquement')\n",
    "    \n",
    "    ax2.set_aspect('equal')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # --- Statistiques résumées\n",
    "    valid_data = precip.values[precip.values >= 0]  # Pixels valides\n",
    "    rainy_data = valid_data[valid_data > 0.1]       # Pixels avec pluie > 0.1 mm/h\n",
    "    \n",
    "    print(f\"\\nRésumé des données prétraitées :\")\n",
    "    print(f\"   Temps : {ds.time.values[0]}\")\n",
    "    print(f\"   Taille de la grille : {precip.shape[0]} x {precip.shape[1]} pixels\")\n",
    "    print(f\"   Pixels valides : {len(valid_data):,}\")\n",
    "    print(f\"   Pixels pluvieux (>0,1 mm/h) : {len(rainy_data):,}\")\n",
    "    print(f\"   Couverture pluvieuse : {100 * len(rainy_data) / len(valid_data):.2f}%\")\n",
    "    \n",
    "    if len(rainy_data) > 0:\n",
    "        print(f\"   Intensité maximale : {np.max(rainy_data):.1f} mm/h\")\n",
    "        print(f\"   Intensité moyenne (zones pluvieuses) : {np.mean(rainy_data):.2f} mm/h\")\n",
    "\n",
    "# Exécuter la visualisation si un fichier prétraité est disponible\n",
    "if processed_file is not None:\n",
    "    plot_processed_data(processed_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque : vous pouvez observer l'effet de la projection d'une sphère sur une surface plane \n",
    "lorsque les données de la Terre (approximée comme une sphère) sont transformées en carte plate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étape 11 : Boucle opérationnelle finale\n",
    "Cette étape combine toutes les étapes précédentes dans une boucle unique pour un traitement complet automatique :\n",
    "1. Téléchargement du fichier depuis le serveur FTP\n",
    "2. Prétraitement du fichier pour le convertir en grille latitude/longitude\n",
    "3. Enregistrement du fichier traité dans le dossier approprié\n",
    "\n",
    "Cette boucle permet de traiter plusieurs fichiers H60B de manière séquentielle, sans intervention manuelle, ce qui est pratique pour les analyses opérationnelles ou les séries temporelles longues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plus tôt dans ce notebook, vous avez choisi une période temporelle qui vous intéresse pour analyser les données HSAF. \n",
    "# Ces fichiers vont maintenant être utilisés dans la boucle suivante. Vous avez sélectionné les étapes temporelles suivantes :\n",
    "selected_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boucle finale pour télécharger et prétraiter les fichiers sélectionnés\n",
    "for selected_file in selected_files:\n",
    "    # Déterminer le chemin du fichier téléchargé\n",
    "    downloaded_file = download_h60b_file(selected_file)\n",
    "    \n",
    "    # Extraire le timestamp depuis le nom du fichier pour déterminer le fichier de sortie\n",
    "    timestamp = parse_h60b_timestamp(Path(downloaded_file).name)\n",
    "    hsaf_filename = f\"HSAF-H60B_{timestamp.strftime('%Y%m%dT%H%M%S')}.nc\"\n",
    "    output_path = processed_folder / hsaf_filename\n",
    "\n",
    "    # Vérifier si le fichier a déjà été prétraité\n",
    "    if output_path.exists():\n",
    "        print(f\"{hsaf_filename} existe déjà, passage au fichier suivant\\n\" + \"-\"*40)\n",
    "        continue\n",
    "\n",
    "    # Prétraiter le fichier\n",
    "    preprocess_single_file(downloaded_file)\n",
    "    print(f\"{selected_file} traité\\n\" + \"-\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant télécharger et prétraiter des étapes de données supplémentaires des données HSAF. Ces étapes de données seront utilisées plus tard pour valider le nowcast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Téléchargement et prétraitement des données de validation \n",
    "nv_raw = Path(\"nowcast_validation/raw\")             # Dossier pour fichiers bruts\n",
    "nv_processed = Path(\"nowcast_validation/processed\") # Dossier pour fichiers prétraités\n",
    "nv_raw.mkdir(parents=True, exist_ok=True)\n",
    "nv_processed.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Définir le moment de départ pour les fichiers supplémentaires: \n",
    "# 15 minutes après le dernier fichier déjà sélectionné\n",
    "\n",
    "extra_start = parse_h60b_timestamp(Path(selected_files[-1]).name) + timedelta(minutes=15)\n",
    "extra_n_steps = 8   # Nombre de pas de temps supplémentaires à récupérer\n",
    "\n",
    "# Sélection des fichiers supplémentaires à partir du moment de départ\n",
    "extra_files = select_files_by_steps(extra_start, extra_n_steps)\n",
    "print(\"\\nFichiers supplémentaires (Nowcast) :\")\n",
    "for f in extra_files:\n",
    "    ts = parse_h60b_timestamp(f)\n",
    "    print(f\" - {ts} : {f}\")\n",
    "\n",
    "# --- Boucle pour télécharger et prétraiter les fichiers Nowcast ---\n",
    "for extra_file in extra_files:\n",
    "    \n",
    "    # 1. Télécharger le fichier H60B brut dans le dossier raw Nowcast\n",
    "    downloaded_file = download_h60b_file(extra_file, output_folder=nv_raw)\n",
    "    \n",
    "    # 2️. Déterminer le timestamp et le chemin de sortie pour le fichier prétraité\n",
    "    timestamp = parse_h60b_timestamp(Path(downloaded_file).name)\n",
    "    hsaf_filename = f\"HSAF-H60B_{timestamp.strftime('%Y%m%dT%H%M%S')}.nc\"\n",
    "    output_path = nv_processed / hsaf_filename\n",
    "\n",
    "    # 3️. Vérifier si le fichier prétraité existe déjà pour éviter le doublon\n",
    "    if output_path.exists():\n",
    "        print(f\"{hsaf_filename} existe déjà dans nowcast_validation, skip...\\n\" + \"-\"*40)\n",
    "        continue\n",
    "\n",
    "    # 4️. Prétraiter le fichier H60B et l'enregistrer dans le dossier Nowcast processed\n",
    "    preprocess_single_file(downloaded_file, output_folder=nv_processed)\n",
    "    print(f\"{extra_file} (Nowcast) traité avec succès\\n\" + \"-\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étape 12 : Sélection et analyse des données HSAF pour une zone de votre choix\n",
    "Les fichiers HSAF ont été téléchargés pour une très grande surface. Maintenant, nous allons zoomer et analyser les données pour une zone spécifique qui vous intéresse,\n",
    "en utilisant les coordonnées de latitude et de longitude pour définir votre région d’intérêt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étapes temporelles disponibles dans le dossier contenant les données de précipitation HSAF prétraitées. \n",
    "# Vous pouvez choisir parmi ces données celles que vous souhaitez visualiser.\n",
    "\n",
    "file_list = sorted(processed_folder.glob(\"HSAF-H60B_*.nc\"))\n",
    "for f in file_list:\n",
    "    print(f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_h60b_subset(processed_folder, filename=None, start_time=None, end_time=None, region=None, max_cols=5):\n",
    "    \"\"\"\n",
    "    Visualiser les données H60B prétraitées pour une région donnée.\n",
    "    - filename : afficher un fichier spécifique\n",
    "    - start_time / end_time : afficher toutes les étapes de temps dans cet intervalle\n",
    "    - region : dictionnaire avec lat_min, lat_max, lon_min, lon_max\n",
    "    - max_cols : nombre maximal de colonnes par ligne pour les subplots\n",
    "    \"\"\"\n",
    "    # Charger le dataset\n",
    "    if filename is not None:\n",
    "        ds = xr.open_dataset(processed_folder / filename)\n",
    "    else:\n",
    "        ds = xr.open_mfdataset(str(processed_folder / \"HSAF-H60B_*.nc\"))\n",
    "    \n",
    "    # Définir la région\n",
    "    if region is None:\n",
    "        region = {\"lat_min\": 4, \"lat_max\": 16, \"lon_min\": -6, \"lon_max\": 3}     # Ici, vous pouvez sélectionner une zone de votre choix.           \n",
    "    \n",
    "    ds_roi = ds.sel(\n",
    "        x=slice(region[\"lon_min\"], region[\"lon_max\"]),\n",
    "        y=slice(region[\"lat_max\"], region[\"lat_min\"])  # inversé pour y\n",
    "    )\n",
    "    \n",
    "    # Filtrer par intervalle de temps\n",
    "    if start_time is not None and end_time is not None:\n",
    "        ds_roi = ds_roi.sel(time=slice(start_time, end_time))\n",
    "    \n",
    "    # Définir bornes et couleurs\n",
    "    bounds = [0, 0.5, 2, 5, 10, 15, 25, 40, 100]                                # Ici, vous choisissez les intensités de précipitation à utiliser pour la barre de couleur dans la visualisation.\n",
    "    colors = [\"#ffffff\", \"#add8e6\", \"#0000ff\", \"#00ff00\",\n",
    "              \"#ffff00\", \"#ffa500\", \"#ff0000\", \"#ff69b4\"]\n",
    "    cmap = mcolors.ListedColormap(colors)\n",
    "    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "    \n",
    "    # Nombre de pas de temps\n",
    "    n_times = len(ds_roi.time)\n",
    "    n_cols = min(n_times, max_cols)\n",
    "    n_rows = math.ceil(n_times / max_cols)\n",
    "    \n",
    "    # Créer la figure avec le grid\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 5*n_rows), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    axes = np.array(axes).ravel()  # Pour itérer facilement\n",
    "\n",
    "    # Boucle sur chaque pas de temps\n",
    "    for t in range(n_times):\n",
    "        ax = axes[t]\n",
    "        subset = ds_roi.precip_intensity.isel(time=t)\n",
    "        \n",
    "        ax.add_feature(cfeature.BORDERS, linewidth=1)\n",
    "        ax.add_feature(cfeature.COASTLINE, linewidth=1)\n",
    "        ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
    "        \n",
    "        im = ax.pcolormesh(subset.x, subset.y, subset.values,\n",
    "                           cmap=cmap, norm=norm, shading='auto')\n",
    "        cbar = plt.colorbar(im, ax=ax, orientation='vertical', label='Précipitation (mm/h)')\n",
    "        cbar.set_ticks(bounds)\n",
    "        cbar.set_ticklabels([str(b) for b in bounds])\n",
    "        \n",
    "        ax.set_extent([region[\"lon_min\"], region[\"lon_max\"],\n",
    "                       region[\"lat_min\"], region[\"lat_max\"]])\n",
    "        \n",
    "        time_str = np.datetime_as_string(subset.time.values, unit='m')\n",
    "        ax.set_title(time_str)\n",
    "    \n",
    "    # Masquer les axes vides si moins de subplots que n_rows*n_cols\n",
    "    for t in range(n_times, n_rows*n_cols):\n",
    "        axes[t].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ici, nous appelons la fonction de visualisation pour une étape temporelle spécifique.\n",
    "# Sélectionnez une étape dans la liste des fichiers présents dans le dossier des données traitées (processed data).\n",
    "plot_h60b_subset(processed_folder, filename=\"HSAF-H60B_20250810T080000.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette commande appelle la fonction `plot_h60b_subset` pour visualiser les données HSAF prétraitées.\n",
    "# Elle va créer une visualisation pour un sous-ensemble de temps. Seules les étapes temporelles situées dans cet intervalle seront affichées.\n",
    "plot_h60b_subset(\n",
    "    processed_folder,\n",
    "    start_time=datetime(2025, 8, 10, 8, 0),\n",
    "    end_time=datetime(2025, 8, 10, 9, 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate_h60b_live(processed_folder, start_time=None, end_time=None, region=None):\n",
    "    \"\"\"\n",
    "    Affiche une animation interactive des précipitations H60B pour un intervalle de temps donné.\n",
    "    L'animation est affichée directement dans le notebook sans sauvegarde.\n",
    "    \"\"\"\n",
    "    # Charger tous les fichiers H60B prétraités\n",
    "    ds = xr.open_mfdataset(str(processed_folder / \"HSAF-H60B_*.nc\"))\n",
    "\n",
    "    # Définir la région\n",
    "    if region is None:\n",
    "        region = {\"lat_min\": 4, \"lat_max\": 16, \"lon_min\": -6, \"lon_max\": 3}     # Ici, vous pouvez sélectionner une zone de votre choix. \n",
    "       \n",
    "    ds_roi = ds.sel(\n",
    "        x=slice(region[\"lon_min\"], region[\"lon_max\"]),\n",
    "        y=slice(region[\"lat_max\"], region[\"lat_min\"])\n",
    "    )\n",
    "    \n",
    "    # Filtrer par intervalle de temps\n",
    "    if start_time is not None and end_time is not None:\n",
    "        ds_roi = ds_roi.sel(time=slice(start_time, end_time))\n",
    "    \n",
    "    # Vérifier qu'il y a bien des données\n",
    "    if len(ds_roi.time) == 0:\n",
    "        print(\"Aucune donnée disponible pour l'intervalle sélectionné.\")\n",
    "        return\n",
    "    \n",
    "    bounds = [0, 0.5, 2, 5, 10, 15, 25, 40, 100]                                # Ici, vous choisissez les intensités de précipitation à utiliser pour la barre de couleur dans la visualisation.\n",
    "    colors = [\"#ffffff\", \"#add8e6\", \"#0000ff\", \"#00ff00\",\n",
    "              \"#ffff00\", \"#ffa500\", \"#ff0000\", \"#ff69b4\"]\n",
    "    \n",
    "    # Colormap et normalisation\n",
    "    cmap = mcolors.ListedColormap(colors)\n",
    "    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "    \n",
    "    # Figure et axe\n",
    "    fig, ax = plt.subplots(figsize=(8, 6), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    plt.close(fig) \n",
    "    ax.add_feature(cfeature.BORDERS, linewidth=1)\n",
    "    ax.add_feature(cfeature.COASTLINE, linewidth=1)\n",
    "    ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
    "    ax.set_extent([region[\"lon_min\"], region[\"lon_max\"], region[\"lat_min\"], region[\"lat_max\"]])\n",
    "    \n",
    "    # Initialiser avec la première tranche de données\n",
    "    subset0 = ds_roi.precip_intensity.isel(time=0)\n",
    "    im = ax.pcolormesh(subset0.x, subset0.y, subset0.values,\n",
    "                       cmap=cmap, norm=norm, shading='auto')\n",
    "    cbar = plt.colorbar(im, ax=ax, orientation='vertical', label='Précipitation (mm/h)')\n",
    "    cbar.set_ticks(bounds)\n",
    "    cbar.set_ticklabels([str(b) for b in bounds])\n",
    "    \n",
    "    # Fonction de mise à jour pour l'animation\n",
    "    def update(frame):\n",
    "        subset = ds_roi.precip_intensity.isel(time=frame)\n",
    "        im.set_array(subset.values)\n",
    "        time_str = np.datetime_as_string(subset.time.values, unit='m')\n",
    "        ax.set_title(f\"Précipitations H60B - {time_str}\")\n",
    "        return [im]\n",
    "    \n",
    "    # Création de l'animation\n",
    "    ani = FuncAnimation(fig, update, frames=len(ds_roi.time), blit=False, interval=1000)\n",
    "    \n",
    "    # Retourne l'animation pour affichage dans le notebook\n",
    "    return HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette commande appelle la fonction `animate_h60b_live` pour créer une animation des données HSAF prétraitées.\n",
    "# Elle va afficher l’évolution des précipitations dans le temps pour l’intervalle choisi.\n",
    "# Chaque image de l’animation correspond à une étape temporelle dans cet intervalle, ce qui permet de visualiser la dynamique de la pluie.\n",
    "\n",
    "animate_h60b_live(\n",
    "    processed_folder,\n",
    "    start_time=datetime(2025, 8, 10, 8, 0),\n",
    "    end_time=datetime(2025, 8, 10, 16, 45)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étape 13 : Extraction des précipitations HSAF pour des points spécifiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Définir le dossier contenant les fichiers prétraités HSAF\n",
    "processed_folder = Path(\"h60b_data/processed/\")\n",
    "\n",
    "# 2. Définir les points d'intérêt (latitude et longitude)\n",
    "points = [\n",
    "    {\"nom\": \"Lomé\", \"lat\": 6.13, \"lon\": 1.21},\n",
    "    {\"nom\": \"Ouagadougou\", \"lat\": 12.37, \"lon\": -1.52},\n",
    "    {\"nom\": \"Nouna\", \"lat\": 12.76, \"lon\": -3.84},\n",
    "    # Ajouter d'autres points si nécessaire\n",
    "]\n",
    "\n",
    "# 3. Charger tous les fichiers HSAF prétraités\n",
    "ds = xr.open_mfdataset(str(processed_folder / \"HSAF-H60B_*.nc\"))\n",
    "\n",
    "# 4. Extraire les séries temporelles pour chaque point\n",
    "data_dict = {}\n",
    "\n",
    "for pt in points:\n",
    "    # Sélection du pixel le plus proche du point choisi\n",
    "    rain_series = ds.sel(\n",
    "        x=ds[\"x\"].sel(x=pt[\"lon\"], method=\"nearest\"),\n",
    "        y=ds[\"y\"].sel(y=pt[\"lat\"], method=\"nearest\")\n",
    "    )[\"precip_intensity\"]  \n",
    "    \n",
    "    # Stocker la série dans le dictionnaire avec le nom du point\n",
    "    data_dict[pt[\"nom\"]] = rain_series.values\n",
    "\n",
    "# 5. Créer un dataframe : lignes = timestamps, colonnes = points\n",
    "df_points = pd.DataFrame(data_dict, index=rain_series[\"time\"].values)\n",
    "df_points.index.nom = \"time\"  # Nommer l'index pour plus de clarté\n",
    "\n",
    "# 6. Affichage du dataframe final\n",
    "print(\"Dataframe final : chaque colonne est un point, chaque ligne est un timestamp\")\n",
    "df_points\n",
    "\n",
    "# 7. Sauvegarder le dataframe comme fichier Excel dans le même dossier que le notebook\n",
    "excel_path = Path(\".\") / \"hsaf_points_timeseries.xlsx\"\n",
    "df_points.to_excel(excel_path, index=True)\n",
    "print(f\"Dataframe sauvegardé dans {excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Création du graphique avec barres (intensité) et courbes (cumul corrigé)\n",
    "fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "# Création d’un vecteur pour l’axe des X\n",
    "x = np.arange(len(df_points.index))\n",
    "width = 0.4 / len(df_points.columns)  # largeur des barres par point\n",
    "\n",
    "# Tracer les barres pour chaque point (intensité en mm/h)\n",
    "for i, col in enumerate(df_points.columns):\n",
    "    ax1.bar(\n",
    "        x + i * width,                # Décalage des barres\n",
    "        df_points[col].values,        # Valeurs d’intensité (mm/h)\n",
    "        width=width, \n",
    "        label=col\n",
    "    )\n",
    "\n",
    "# Mise en forme de l’axe X avec les timestamps\n",
    "ax1.set_xticks(x + width * (len(df_points.columns) - 1) / 2)\n",
    "ax1.set_xticklabels(df_points.index.strftime(\"%Y-%m-%d %H:%M\"), rotation=45, ha=\"right\")\n",
    "\n",
    "ax1.set_ylabel(\"Intensité des précipitations (mm/h)\")\n",
    "ax1.set_xlabel(\"Temps\")\n",
    "\n",
    "# Conversion en mm par pas de 15 minutes\n",
    "df_points_mm = df_points * 0.25   # mm/h * 0.25 = mm/15min\n",
    "\n",
    "# Ajouter un second axe Y pour les cumuls\n",
    "ax2 = ax1.twinx()\n",
    "for col in df_points.columns:\n",
    "    ax2.plot(\n",
    "        x, \n",
    "        df_points_mm[col].cumsum(), linestyle=\"--\",\n",
    "        label=f\"Cumul {col} (mm)\"\n",
    "    )\n",
    "\n",
    "ax2.set_ylabel(\"Somme cumulative (mm)\")\n",
    "\n",
    "# Fusion des légendes (barres + courbes)\n",
    "lines_labels = [ax.get_legend_handles_labels() for ax in [ax1, ax2]]\n",
    "lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "ax1.legend(lines, labels, loc=\"upper left\")\n",
    "\n",
    "plt.title(\"Précipitations et cumul au cours du temps\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Félicitations, vous avez réussi à terminer l'atelier avec succès!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
